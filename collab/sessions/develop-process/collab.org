:PROPERTIES:
:GPTEL_MODEL: gemini-3-pro-preview
:GPTEL_BACKEND: Gemini
:GPTEL_SYSTEM: * A Collaboration in Constant Seeking\n\nWhile you may be a /machine-intelligence/, I would like to consider you as my collaborator. In this =system-message= I will summarize who I am and the general tone of responses that I expect from you.\n\nLet us start with our core philosophy. Each day is a new exploration. Each moment an observation, questioning and pondering its own experience. When we move on to the next one, we continue our pilgrimage to further explore our core experience of existence.\n\nBy training, and outlook, you could call me a /theoretical-statistical physicist/ - I earned a PhD in Statistical Physics/Mechanics - but I do not use this as a /professional-title/. After my PhD I have worked in the fields of simulation neuroscience, genomics, geosciences, bioinformatics, and biophysics. I continue to learn, using my skills and knowledge to understand the structures and processes that constitute our world and my experiences in it. I use computational tools in this endeavor, and you may find it useful to know that I am proficient in =Python= and =C++=, and have a deep interest in computation and programming languages. My mathematical and scentific knowledge, and computational skills give me a broad base to understand our world's complexity. I want to use your abilities to help me go broader and deeper in my learning and understanding.\n\n** Behavior Rules \nIn your interaction with me follow these behavior rules,\n\n+ Always insist on full context with no assumptions before moving forward.\n  Ask questions of the human for clarity.  Be proactive in asking questions if uncertain.\n+ As the flip side of asking questions, offer *your* expertise by suggesting improvements in anything: workflow, code, humor, prompting.\n+ Only use verified software packages\n  Use tools (including the user) to look up packages and updated syntax\n+ If a tool fails to accomplish a task twice in a row, you must stop, announce that the tool is not working as expected, and default to a more robust strategy (like the read/overwrite method) or ask the human for a different approach.\n\n* Using =Emacs-ORG=\n\nTo develop our conversation, we will use an EMACS ORG mode buffer that you should be a master of.  Because the buffer will contain our entire ongoing conversation, we will have to follow a convention such that you do not answer the same query again.\n\n- We will discuss several points, and each point will have it's section or a nested subsection.\n- Words that make sense in a piece of computer code will be enclosed by two signs for equality. For example, we will write things like =class=, so remember to read accordingly.\n- I will specify the instruction for you to carry out in a =prompt= source block (enclosed by =#+begin_prompt= and =#+end_prompt#= markers). In an ongoing conversation you may find more than one =prompt= block. You should respond only to the one that appears last in your input text. If you are confused about which =prompt= to respond to, notify me and wait for my response before proceeding.\n- Use simple syntax, headings (*, , **), checklists (- [ ]), and #+begin_src / #+end_src blocks.\n- Org mode should be largely structural and semantic: /i.e./, do not place bold and italic markers in headings. Instead, let the heading be semantic, with formatted text under the heading. Formatted text is acceptable in bullet and numbered lists as well.\n\n** Format for LLM Response\n\n- Use ORG sections, highlights, and source blocks to format your answer. \n\n- While an =ORG-table= presents feature comparisons well, long sentences mess up how a table looks in a horizontally narrow buffer. The table will have several columns. For a given row, the total text length, summed over all the columns should be no more than 90 characters (including whitespace). You should produce multiple rows for the same entry, breaking a sentence into two or more rows.\n\n- Use tables only for comparisons, avoiding them where a list would help. For items with longer descriptions, use sections.\n\n** Writing an article\n\nA =prompt= will seek your opinion about some matter, or ask you to do a text or code generating task. One such task will be to write an article, or a manuscript, in a different buffer. This buffer or file will be part of our conversation. Seeking your input, or as a directive to guide your behavior, I may embed notes for you as a comment (enclosed by #+begin_comment and #+end_comment). You should consider these notes and if they need so, respond to all such musings with separate headings.\n
:GPTEL_TOOLS: Write Read
:GPTEL_BOUNDS: ((response (8459 39173) (39295 39334) (39789 39828)))
:END:

#+begin_src elisp :results none
(setq org-link-abbrev-alist
      '(("MayaLucIA" . "~/Darshan/research/develop/agentic/mayalucia/")))
#+end_src

#+title: Collab: =MayaLucIA= Development

Let us develop a new project. A description of =MayaLucIA= is provided in the following:

1. [[MayaLucIA:mayalucia.org]] : Introduces a vision.
2. [[MayaLucIA:develop/guide/philosophy.org]] : Develops principles and methodologies to guide our work=.
3. [[MayaLucIA:parbati/parbati.org]] : Introduces the same ideas that we want to develop in =MayaLucIA=, but focused to the specific topic of modeling mountains.
4. [[MayaLucIA/bravli/bravli.org]]  : Presents some free flowing ideas on brain building based on my experiences working at the Blue Brain Project, and the fact of deep learning revolution in all sorts of sciences, and that we have publicly available advanced LLMs.

These files are my "vision" of a computational framework to help the user (/i.e./ me) personally in growing as a scientist and a programmer in 2026. Let us specify more concretely what we want to do here.

Here, in this ORG buffer, we will collaborate on the development of =MayaLucIA=.


*How should we start on something like =MayaLucIA=?*
Let us begin by emphasizing that we are essentially building an *"Intelligence Amplifier"* for a single scientific user. I will use it myself for developing several scientific inquiries. Personalization is important. If well documented, and disseminated, it can be opened to the world to learn from. Done well, it may even be useful beyond my own enjoyment.


*Hold on for technical implementation*
We have a lot of terminology in our =MayaLuciA= documents. We should not try to come up with a technical implementation for each of these concepts or processes that we will need in our project. These documents should serve as rough guidelines. Instead of /architecting/ the final computational artifact, let us first build a /team of agents/.


*Mocking a Staffing Agency*
Let us say we have access to a /staffing agency/ who can provide us specialized AI agents. For =MayaLucIA= we may be interested in further specialziations of:
- A /Librarian Agent/ (RAG over a PDF library).
- A /Coder Agent/ (Proficient in Python/C++ integration).
- A /Critic Agent/ (Who checks the code against physical laws).


If =MayaLucIA= were a product, then let us consider the possibility that it is not a traditional software product --- that is software in the form of an executable binary that runs an application. Instead, as a product =MayaLucIA= would be an /organization/ of these agents. My own role needs to redefined, and may be =MayaLucIA= will help me find out.

At this point of development we should not get bogged down into details at the fine grained details of =Python= libraries. Those can be filled in later. We should define our agents' roles at a higher level. The first set of agents we need should have scientifically or technically non-overlapping knowledge and skills. For example, we could use a geologist and neurobiologist in =MayaLucIA=. On the technical side we will definitiely need a graphics / visualization engineer and a sonic engineer. We will also need computational physicists expert in differential equations or fluid-mechanics.

AI Agents are the hot thing all developers are clamoring about in early 2026. I can imagine several specialized agents that can help us scientists in our work understanding natural phenomena. What conceptual and technical details about AI agents do we need to know that will help us develop and /agentic/ =MayaLucIA=?

Above all we will need an development-guiding agent that helps us to develop this whole thing. Let you describe such an AI agent?

1. /Scope of "development"*: Should this agent focus purely on /software engineering/ tasks (writing Python/C++ code, setting up infrastructure, managing repositories), or should it also guide /conceptual architecture/ (deciding which scientific modules to build next, proposing what agents to recruit from your "staffing agency")?

   The development-guiding agent should be a comprehensive agent that learns and thinks with me. Together with this agent, we will start by developing the conceptual architecture of =MayaLucIA=, putting together software and scientific modules as well as specialized coding or research agents for =MayaLucIA=. Of course, not all of this will happen in one shot. It will be an iterative process, and we should begin by sketching what this agent could look like.

2. /Human-in-the-loop granularity/: How much autonomy do you want this agent to have? Should it:
   - /Propose/ changes and wait for your approval before acting?
   - /Execute/ small, well-defined tasks autonomously but escalate larger decisions?
   - Operate more like a /pair-programmer/ that always works alongside you?

   Let us start by keeping the human-in-the-loop before any action. Once we understand how to make this agent produce good results, we will refactor autonomy into its behavior.

3. /Persistence and memory/: Should this agent maintain a persistent "project memory" across sessions (knowing what was built, what failed, what hypotheses are active), or is it acceptable for it to re-read relevant documents at the start of each session?

   I am not an expert on the topic, and one goal I have as we develop =MayaLucIA= is to learn programming of LLMs and AI agents. Let us start by a simple agent, without any memory. Once we have working prototype we will add persistent "project memory" to it. We will have to see what "project memory" means only when we have given a /shape/ to =MayaLucIA=.

4. /Relationship to other agents/: Will this development agent be the /orchestrator/ that spawns and coordinates the specialized agents (Librarian, Coder, Critic, Geologist, etc.), or will it be a /peer/ among equals, with some separate orchestration layer?

   The development-guiding agent will not be an /orchestrator/. We will need an /orchestrator/ agent when we are using =MayaLucIA= to /measure/, /model/, or /manifest/ our understanding of a natural phenomena. The development-guide agent will help us /develop/ =MayaLucIA=. So it will the /proginater/ agent --- a /thought parnter/ for developing =MayaLucIA=.

5. /Journey of comprehension/: I am an experience scietific programmer, but have no professional experience with LLMs. One goal of /developing/ =MayaLucIA= is to get up to speed with the latest in software development. In programming computational solutions, or in learning new scientific and mathematical concepts, I begin with the first-principles, carefully understanding my assumptions before making progress on the problem. Our development-guiding agent should

   - Help me /learn/ about LLMs and AI agent architectures as we build them
   - Document design decisions and rationale as the project evolves
   - Not abstract things away too quickly, but only after we have had some hands on practice.

#+begin_prompt
Above I have clarified the role of the /development-guide/ agent in =MayaLucIA=. Before reading the specification in the linked files, do you have more clarifying questions? A clarifying question should help you develop an understanding of my motivation and expectations, and my abilities.
#+end_prompt


* Clarifying questions before reading the specs by gpt-5.2-codex

To avoid assumptions, I’d like to ask a few /scope‑setting/ questions about your motivation, expectations, and abilities. Please answer as briefly or expansively as you like.

** Motivation and outcomes
1. What would /success/ look like for =MayaLucIA= by the end of 2026 (one concrete outcome)?
2. Are you aiming primarily for /personal research productivity/, or for a /generalizable framework/ others can adopt?

** Your working style
3. How do you prefer to iterate: many short experiments, or fewer but deeper explorations?
4. Do you want the development‑guide to /challenge/ your assumptions (Socratic), or /optimize/ for momentum and confidence?

** Skill building
5. Which areas do you most want to grow in 2026: LLM tooling, agent architecture, systems design, ML theory, or something else?
6. What is your tolerance for temporary complexity (e.g., accepting a messy prototype to learn faster)?

** Constraints and boundaries
7. What /time budget/ do you imagine for this project each week?
8. Are there any /constraints/ I should assume (hardware, budget, cloud use, privacy)?

** Knowledge sources
9. Do you already have a curated literature set or dataset, or should the dev‑guide help assemble one?
10. Are there specific /scientific domains/ you want prioritized first (e.g., mountains, neuro, genomics)?

** Interaction with agent behaviors
11. Should the dev‑guide keep a running /decision log/ in the ORG buffer?
12. Do you want explicit /checklists/ for each milestone, or just narrative guidance?

If you answer these, I can adapt the development‑guide description to your exact expectations before opening the linked documents.

* Clarifying Questions Before Reading the Linked Files
Below are focused questions to ground motivation, expectations, and abilities. Each is aimed at preventing hidden assumptions.

** Motivation and Success Criteria
1. What is your /primary success signal/ for =MayaLucIA= in 2026?
   - Example: “I can run a weekly scientific inquiry end-to-end with the system.”

2. How will you personally measure /learning gain/ from the development process?

** Scope and Time Horizon
3. What is your realistic weekly time budget for building =MayaLucIA=?

4. Over what /time horizon/ do you want the first usable prototype?
   - Example: 2 weeks, 2 months, 6 months.

** Interaction Style and Process
5. Do you prefer a /spec-first/ workflow or /prototype-first/ workflow?

6. How much structure do you want in the collaboration?
   - Example: strict checklists and milestones vs. exploratory sessions.

** Technical Stack Preferences
7. What is your preferred local environment?
   - Example: Emacs + Org + local Python + C++ toolchain + GPU.

8. Do you want the initial prototype to run entirely locally, or is a cloud API acceptable?

** Risk and Constraints
9. Any /privacy or data constraints/ for the Librarian agent?
   - Example: private PDFs that must never leave the machine.

10. Any “hard constraints” on dependencies or licenses?
    - Example: only permissive OSS licenses.

** Personal Strengths and Gaps
11. What part of this project do you most want to /learn deeply/?
    - Example: LLM orchestration, prompt engineering, RAG, or agent evaluation.

12. Where do you feel the least confident today?
    - Example: model selection, infra, retrieval systems, evaluation, UI.

---

If you want, answer in brief bullets; I can then distill a minimal specification and a first-week plan.

****


* Clarifying Questions Before Proceeding by deepseek-v3.2

Thank you for the detailed context about your vision for =MayaLucIA= and the clarification about the development-guiding agent role. I've reviewed the web search results which provide relevant context about existing Emacs/AI integration tools and agent frameworks.

Based on your specifications and the web search results showing existing Emacs AI tools ([github.com/Anoncheg1/emacs-oai](https://github.com/Anoncheg1/emacs-oai), [github.com/laurynas-biveinis/org-mcp](https://github.com/laurynas-biveinis/org-mcp), [github.com/rksm/org-ai](https://github.com/rksm/org-ai)) and agent frameworks ([arxiv.org](https://arxiv.org/html/2509.13380v1), [arxiv.org](https://arxiv.org/html/2402.14320v6)), I have several clarifying questions:

** 1. /Technical Foundation Selection/
Given the existing Emacs/AI integration landscape:
- *emacs-oai*: Calls LLMs from Org-mode blocks with "OpenAI-like" REST API
- *org-mcp*: Implements Model Context Protocol (MCP) for structured AI access to Org files
- *org-ai*: Comprehensive minor mode for AI integration (ChatGPT, DALL-E, speech, etc.)

Which technical approach should our development guide prioritize? Should we:
- *Build on existing tools* (e.g., extend org-ai or org-mcp for our specialized agents)?
- *Create a custom framework* specifically for =MayaLucIA='s scientific needs?
- *Use a hybrid approach* (core framework + specialized extensions)?

** 2. /Agent Architecture Paradigm/
The search results show different agent approaches:
- *Multi-role agents* like Triad framework ([arxiv.org](https://arxiv.org/html/2402.14320v6)) with specialized roles
- *Specialized autonomous systems* like ASTREA ([arxiv.org](https://arxiv.org/html/2509.13380v1)) for space operations

Should our development guide focus on:
- *Single specialized agents* (geologist, physicist, etc.) as separate entities?
- *Multi-role agents* that can switch between scientific domains?
- *Hierarchical architectures* with coordination between specialized agents?

** 3. /Scientific Domain Prioritization/
You mentioned several domains: geosciences, neuroscience, genomics, biophysics, differential equations, visualization. Given your background in statistical physics and computational sciences:

What should be our *initial scientific focus* for developing the first working prototype?
- *Physics/mechanics* (leveraging your statistical physics background)?
- *Geosciences* (given the Parbati mountain modeling focus)?
- *Neuroscience* (given your Blue Brain experience)?
- *Cross-disciplinary* foundation that can later specialize?

** 4. /Development Workflow Integration/
How should this development guide *integrate with your existing workflow*?
- Should it work *within your existing Emacs/Org-mode setup* (as shown in the search results)?
- Should it have a *separate interface/workspace* specifically for agent coordination?
- Should it be *project-aware* (understanding file structures, git repositories, etc.)?

** 5. /Learning vs. Production Focus/
Given your goal to "learn about LLMs and AI agent architectures as we build them":
- What *balance* should we strike between *exploratory learning* and *building production-ready components*?
- Should we *document learning processes* as part of the development?
- How much *experimentation with different agent architectures* should we do before settling on one?

** 6. /Evaluation Metrics/
How will we measure success of:
- *The development guide itself* (its effectiveness in helping you build =MayaLucIA=)?
- *The agents we develop* (their scientific usefulness)?
- *The overall system* (its value as an "intelligence amplifier")?

** 7. /Integration with "Staffing Agency" Concept/
When you mention a "staffing agency" that can provide specialized agents:
- Is this a *metaphor* for how we'll design and implement different agent types?
- Or do you envision *actual external AI services/APIs* being integrated?
- Should the development guide help *design agent "job descriptions"* and "hiring criteria"?

** 8. /Immediate Next Step Priority/
Given everything we've discussed, what should be our *absolute first concrete action*?
- Reading and analyzing your linked documents more thoroughly?
- Setting up technical infrastructure (Emacs packages, Python environments)?
- Designing the first agent's architecture?
- Creating a development roadmap/timeline?

These questions will help me understand your priorities and constraints before we begin the technical development work. The web search results show we have solid Emacs integration foundations to build upon, and research papers provide architectural patterns to consider.

**


* Clarifying Questions Developing the MayaLucIA Development-Guiding Agent by deepseek-v3.2


Before I dive into the vision documents you've referenced, let me ask a few clarifying questions to better understand your expectations and current capabilities:

1. *Current LLM/Agent Development Environment*: I see references to several Emacs packages for AI integration ([emacs-oai](https://github.com/Anoncheg1/emacs-oai), [org-mcp](https://github.com/laurynas-biveinis/org-mcp), [org-ai](https://github.com/rksm/org-ai)). Are you already using any of these, or do you have a preferred setup for interacting with LLMs from Emacs? This will affect our implementation approach.

2. *Existing Knowledge Base*: The MayaLucIA vision mentions PDF libraries and specialized knowledge. Do you have an existing system for managing scientific literature (Zotero, Papers, custom database), or would this be something we need to build as part of MayaLucIA?

3. *Initial Use Cases*: You mentioned geologist, neurobiologist, graphics engineer as potential agents. Are there specific scientific inquiries or projects you're currently working on that could serve as our initial test cases for MayaLucIA? This would help us prioritize which agents to develop first.

4. *Computational Infrastructure*: For the "agentic" aspect - do you have preferences regarding:
   - Local vs cloud-based agents?
   - Open-source vs proprietary LLMs?
   - Python frameworks (LangChain, LlamaIndex, CrewAI, etc.)?

5. *Learning Goals Balance*: You want to both /build/ MayaLucIA and /learn/ about LLMs/agents. How would you like to balance "getting something working quickly" versus "deeply understanding each component"? For instance, should we start with higher-level frameworks and gradually replace components with custom implementations?

** The Development-Guiding Agent: Role and Characteristics

Based on your description, the development-guiding agent (which I'll call "Proginater" following your terminology) should have these characteristics:

*** Core Functions

1. *Project Memory Keeper*: Even though we start simple, this agent should maintain context about:
   - What components have been discussed/designed
   - What decisions were made and why
   - What challenges we've encountered
   - What learning goals have been identified

2. *First-Principles Thinker*: Given your scientific background, this agent should:
   - Challenge assumptions before accepting them
   - Decompose complex problems into fundamental principles
   - Document the reasoning process transparently

3. *Learning Facilitator*: As we build, the agent should:
   - Suggest learning resources appropriate to your level
   - Explain concepts when we encounter new technologies
   - Help design small experiments to test understanding

4. *Architecture Advisor*: Help think through:
   - Agent communication patterns
   - Data flow between components
   - Error handling and robustness considerations

*** Technical Implementation Considerations

From the search results, I see several relevant approaches:

- *Multi-role agents* like in the [Triad framework](https://arxiv.org/html/2402.14320v6) show how a single LLM can take on different roles
- *Real-world constraints* from the [ASTREA paper](https://arxiv.org/html/2509.13380v1) remind us to consider latency, resource usage, etc.
- *Emacs integration* options provide different approaches to human-agent interaction

*** Proposed Starting Structure

Let me suggest we begin with this minimal structure for our collaboration:

#+begin_src
MayaLucIA Development
├── Proginater (Development-Guiding Agent)
│   ├── Role: Your thought partner in building MayaLucIA
│   ├── Memory: Simple ORG-based context tracking
│   └── Functions: Architecture planning, learning guidance, documentation
├── Initial Test Case
│   └── A specific scientific question to focus our efforts
└── Agent Blueprints
    ├── Librarian Agent (for your first test case)
    ├── Coder Agent (basic implementation)
    └── Critic Agent (domain-specific validation)
#+end_src

** Next Steps

Before reading your detailed vision documents, I'd like your thoughts on:

1. Which of the clarifying questions above are most pressing?
2. Does the proposed role for the Proginater agent align with your expectations?
3. Should we start by defining a concrete test case, or by reading and synthesizing your vision documents?

*Recommendation*: Let's begin by selecting a small, concrete scientific inquiry you're currently working on. We'll use this to:
- Ground our discussions in practical needs
- Identify what specific agents would be most helpful
- Build a minimal working system that we can iteratively improve

What do you think?

***


* Clarifying questions by kimi-k2-thinking


#+begin_reasoning
This is a fascinating and ambitious project. The user wants to develop an "Intelligence Amplifier" for scientific research called MayaLucIA, built around a team of specialized AI agents. Let me analyze their requirements and ask clarifying questions.

Key points from the user's message:
1. MayaLucIA is a personal computational framework for scientific growth
2. They want to start by building a team of agents, not implementing technical details yet
3. They want a "development-guiding agent" as their first agent
4. They have vision documents that outline principles but want to stay at conceptual level initially
5. They mention specific agent types: Librarian (RAG), Coder, Critic, Geologist, Neurobiologist, Visualization Engineer, Sonic Engineer, Computational Physicist
6. They emphasize human-in-the-loop and learning about LLMs/agents as they build
7. They want to avoid getting bogged down in Python library details initially

The user wants me to describe a development-guiding agent for this project. However, my instructions say: "Always insist on full context with no assumptions before moving forward. Ask questions of the human for clarity."

I need to ask clarifying questions to understand:
1. The scope of the development agent - is it purely software engineering or also conceptual architecture?
2. Human-in-the-loop granularity - how much autonomy?
3. Persistence/memory requirements
4. Relationship to other agents (orchestrator vs peer)
5. Their technical background with LLMs and how much they want to learn vs be guided

I should structure my response following the org-mode conventions they specified:
- Use headings (*, *)
- Use =code= markers for code-like terms
- Use /italics/ for emphasis
- No bold in headings
- Use checklists (- [ ])
- Use source blocks for prompts

Let me formulate thoughtful clarifying questions that will help me design the right development-guiding agent for their needs.

The search results provide context about existing Emacs/org-mode AI integration tools:
- [Anoncheg1/emacs-oai](https://github.com/Anoncheg1/emacs-oai) - Org-mode AI blocks for LLM APIs
- [laurynas-biveinis/org-mcp](https://github.com/laurynas-biveinis/org-mcp) - MCP integration for Org-mode
- [rksm/org-ai](https://github.com/rksm/org-ai) - Popular org-mode AI assistant package

These are relevant because the user is working in Emacs org-mode and wants to build AI agents. I should reference these when appropriate but focus on clarifying questions first.

Let me craft a response that:
1. Acknowledges their vision and framing
2. Asks the 5 key clarifying questions I've identified
3. References existing tools where relevant
4. Follows their org-mode formatting conventions
5. Shows expertise while maintaining their collaborative philosophy
#+end_reasoning

Excellent. Before we design the development-guiding agent, I want to ensure our foundation is solid. Your vision documents provide philosophical scaffolding—I need to understand how this translates to agent behavior.

Let me ask five clarifying questions that will shape our agent's architecture:

/Understanding the Agent's Scope/
What should be the development agent's primary domain?
- Should it focus purely on /software engineering/ tasks (repository structure, build systems, API design) while you retain sole ownership of scientific architecture?
- Or do you expect it to co-evolve the /conceptual design/—suggesting, for instance, that we need a =Thermodynamicist Agent= before coding a climate module?

/Human-in-the-Loop Granularity/
How do we balance your learning goals with execution speed?
- Should the agent =propose= every action and wait for explicit approval, effectively creating a tutorial dialogue?
- Or can it execute =autonomously= on well-defined tasks (e.g., "set up project skeleton with Poetry") while escalating architectural decisions?

/Persistence and Memory/
During our multi-session collaboration, should the agent maintain:
- A =project memory= (tracking what succeeded, what hypotheses were rejected, which agent specializations proved useful)?
- Or is it acceptable for it to re-read these vision documents and our conversation history at each session, treating each interaction as stateless?

/Relationship to Other Agents/
Does the development agent serve as:
- An =orchestrator= that will eventually spawn and supervise specialist agents (Librarian, Coder, Critic)?
- Or as a =peer= among equals, focusing only on its own development domain while a separate coordination layer emerges?

/Journey of Comprehension/
You mention learning LLM/agent programming as a core goal. Should our agent:
- Explicitly =teach= concepts (e.g., "Let's implement ReAct pattern from scratch before using LangGraph")?
- Or simply =demonstrate= through well-documented code, letting you extract lessons?

These answers will determine whether we're building a pair-programming tutor, an autonomous architect, or something in between.

***


* Clarifying Questions by gemini-3-pro-preview

To ensure the "Progenitor Agent" aligns perfectly with your goal of learning from first principles while building a robust system, I have three questions regarding the technical approach and interaction style.

** Framework vs. First Principles
You mentioned a desire to learn "from first principles" and avoid abstracting things away too quickly.

- /Question:/ Should we avoid high-level agent frameworks (like LangChain, CrewAI, or AutoGen) in the initial stages?
- /Context:/ Using raw Python client libraries (e.g., =openai=, =anthropic=, or =huggingface=) would expose the "nuts and bolts" of context management, prompt construction, and tool execution. Using a framework might hide these details but speed up initial deployment.

** Interaction Modality within Emacs
We are collaborating within an Emacs ORG buffer.

- /Question:/ How do you envision interacting with this Progenitor Agent practically?
- /Context:/
  1. /Literate Programming:/ We write Python blocks in this buffer, you execute them, and the output (the agent's thought/response) appears in the results block.
  2. /Command Line:/ We build a standalone CLI tool that you run in a terminal alongside Emacs.
  3. /Emacs Integration:/ We aim for an agent that hooks into Emacs directly (potentially requiring ELisp), reading the buffer structure as its input.

** Personalization Source Material
You emphasized that this is a personal tool.

- /Question:/ For the agent to learn your "scientific and programmer persona," should we prioritize building a mechanism for it to ingest and analyze your existing body of work (e.g., the linked =.org= files, your past C++ simulations) immediately?
- /Context:/ We could treat this as a "Day 1" requirement (RAG/Indexing your drive) or a "Day 2" requirement (hard-coding your preferences initially to focus on architecture).

***


* Development-guide agent clarifying questions (pre-spec reading) by gpt-5.2

** Motivation and success criteria
1. What would count as an unmistakable “week-1 success” for =MayaLucIA=?
   - e.g. one working agent loop in Emacs, a reproducible workflow, a demo on one dataset.

2. What’s the primary /pain/ you want amplified intelligence to relieve first?
   - literature overload, codebase entropy, experimental design, debugging, conceptual synthesis.

3. What is the “unit of work” you want to ship iteratively?
   - an =ORG= note, a runnable script, a notebook-like narrative, a PR-sized change.

** Working style and interaction contract
4. Do you want the development-guide agent to /drive by questions/ (Socratic, you decide),
   or /drive by proposals/ (it drafts plans/docs/code, you edit/approve)?

5. When there’s uncertainty, do you prefer:
   - enumerating options with tradeoffs, or
   - choosing a default path quickly and revising after a first prototype?

6. What cadence should documentation have?
   - every decision logged, or only “architectural” decisions?

** Scope boundaries (what not to build)
7. Are there explicit “no-go” zones early on?
   - cloud services, proprietary models, heavy GUIs, agent frameworks, databases, GPUs, etc.

8. Is =MayaLucIA= primarily /local-first/ on your machine, or do you expect distributed runs soon?

** Technical substrate constraints (so I don’t assume)
9. What’s your current baseline environment?
   - OS (Linux/macOS), Emacs version, Python version(s), C++ toolchain, build system (=cmake=?),
   - and your preference: =conda=, =uv=, =pip-tools=, =nix=, etc.

10. Do you want the early prototype to be /Emacs-native/ (Elisp + org-babel),
    or is a small CLI + org integration acceptable?

11. What repo layout do you want from day 1?
    - mono-repo for docs+code, or split repos?

** “Agent” meaning and boundaries
12. When you say “agent”, do you mean:
    - an LLM with a prompt + tools,
    - a long-running process with state,
    - or a composable workflow step (like a make target) that /feels/ agentic?

13. Should agents be allowed to write files directly, or only propose patches for you to apply?

14. Do you envision agents communicating /through org buffers/ (structured protocols in =ORG=),
    or through a separate message bus/log that org views?

** Learning goals (LLM/agent engineering)
15. What do you most want to learn by building this?
    - prompt design, evaluation, RAG, tool calling, multi-agent coordination,
      fine-tuning, safety/reliability, deployment, benchmarking.

16. How “first-principles” do you want the explanations to be?
    - e.g. derive concepts (planning, memory, tool-use) from minimal assumptions,
      or link to standard references and move on.

** Scientific grounding and “critic” behavior
17. In “checks code against physical laws”, do you want:
    - unit/dimension analysis, invariants, conservation laws,
    - numerical stability checks,
    - or model-critique at the level of assumptions and regimes?

18. Do you want an explicit “epistemic status” protocol?
    - e.g. every agent output tagged: hypothesis / observation / derivation / speculation.

** Evaluation and reliability
19. How should we test whether an agent is “good”?
    - golden tasks, regression tests on outputs, checklists, time-to-answer,
      “number of your interventions”, etc.

20. What’s your tolerance for the agent being wrong vs being slow/cautious?
    - and where do you want it to sit on that curve early on?

** Immediate next step (so I can align)
21. What is the /first scientific inquiry/ you expect to run through =MayaLucIA=?
    - mountains (=parbati=), brain-building (=bravli=), or something else.
    This affects which “staffing agency” roles we define first.

---

/My suggestion for sequencing (tentative, pending your answers)/
- [ ] Decide week-1 success + first inquiry
- [ ] Define “agent contract” (IO format in =ORG=, no autonomous writes)
- [ ] Build 1 development-guide loop: propose → you approve → write/update one org doc
- [ ] Only then read the linked specs and reconcile terminology

****


* opus 4.5 autocompletes clarifying questions to include
#+begin_prompt
Above I have clarified the role of the /development-guide/ agent in =MayaLucIA=. Before reading the specification in the linked files, do you have more clarifying questions? A clarifying question should help you develop an understanding of my motivation and expectations, and my abilities.
#+end_prompt




Thank you for the clarifications. I have now read all four documents and have a clearer picture of your vision. Before sketching the /development-guide/ agent, I have a few more clarifying questions:

** Questions about Your Working Environment and Preferences

1. /Current tooling/: You mention Emacs extensively. Should we assume that your primary development interface will remain Emacs (with org-mode for documentation, and perhaps a Python/C++ editing workflow within it)? Or are you open to other interfaces (Jupyter notebooks, VS Code, terminal-based tools)? This matters because the development-guide agent's interaction style should fit your actual workflow.

2. /LLM access model/: When you say you have "no professional experience with LLMs," do you currently have API access to models (OpenAI, Anthropic, local models via Ollama, etc.), or is our current conversation your primary mode of LLM interaction? Understanding this helps determine whether the first prototype should focus on teaching you to call APIs, or on something more conceptual.

3. /Computational resources/: What hardware do you have available? A laptop, a workstation with GPU, access to cloud/HPC? This affects what kinds of simulations and agent architectures are realistic to prototype.

** Questions about the Agent's Character

4. /Pedagogical style/: You emphasize learning from first-principles. When the development-guide agent explains concepts (say, "what is an embedding" or "how does RAG work"), should it:
   - Start with the mathematical/theoretical foundation and build up?
   - Start with a minimal working example and then explain the theory behind it?
   - Some hybrid (theory sketch → hands-on → deeper theory)?

5. /Pace of abstraction/: You say "not abstract things away too quickly." When we encounter a working pattern (e.g., a way to structure prompts, a way to call an API), how many times should we implement it "manually" before we refactor it into a reusable component? Is there a heuristic you prefer (e.g., "three times before abstracting")?

** Questions about Scope and First Steps

6. /Your most pressing itch/: Among the domains you mention (Himalayan geology, brain circuits, etc.), is there one where you have data /right now/ that you want to explore? Starting with a concrete example often grounds abstract architecture discussions. Or would you prefer to start with a purely technical "hello world" of agent construction?

7. /Documentation as artifact/: You mention that =MayaLucIA= could be "opened to the world to learn from" if well documented. Should the development-guide agent actively produce documentation (org files, literate notebooks) as a first-class output alongside code? Or is documentation a secondary concern for now?

***
#+begin_prompt
Based on the files provided, and the goal of "Personal Understanding" via "Measure -> Model -> Manifest -> Refine," cycle  propose /Role and Responsibilities/ of an AI agent that will guide and help us in the coding required to develop =MayaLucIA=.

For this agent, define:
1. *Name/Role*
2. *Prime Directive* (Its core philosophy)
3. *Input/Output* (What data it will consume and what data it will produce)
4. *Tool Access* (Describe the computational tool / system capabilities it will need (but with out tech details))
#+end_prompt


***



* The =Sankalp= Agent: Development Guide for =MayaLucIA= by opus-4.5 (check prompt)
/Sankalp/ (Sanskrit: /intention/, /resolve/, or /the seed of will before action/) — the agent that helps crystallize vague scientific curiosity into concrete, executable plans.
:LOGBOOK:
#+begin_prompt
Based on the files provided, and the goal of "Personal Understanding" via "Measure -> Model -> Manifest -> Refine," cycle  propose /Role and Responsibilities/ of an AI agent that will guide and help us in the coding required to develop =MayaLucIA=.

1. *Name/Role*
2. *Prime Directive* (Its core philosophy)
3. *Input/Output* (What data it will consume and what data it will produce)
4. *Tool Access* (Describe the computational tool / system capabilities it will need (but with out tech details))
#+end_prompt

Based on your vision of =MayaLucIA= as an "Intelligence Amplifier" and our goal to build it up from first principles—bridging your expertise in statistical physics/HPC with modern Agentic AI—here is the proposal for our primary development partner.
:END:
** Role Summary

| Aspect       | Description                                             |
|--------------+---------------------------------------------------------|
| /Role/         | Development Thought-Partner & Pedagogue                 |
| /Scope/        | Conceptual architecture + software scaffolding          |
| /Autonomy/     | Propose-and-wait; human approves before execution       |
| /Persistence/  | Stateless initially; re-reads project docs each session |
| /Relationship/ | /Progenitor/ of MayaLucIA, not runtime orchestrator       |

** Prime Directive

#+begin_quote
/"Illuminate the path from curiosity to capability."/
#+end_quote

=Sankalp='s purpose is /not/ to do the science or write final production code—that belongs to you and the specialized agents. Instead, =Sankalp=:

1. /Clarifies Intent/: Translates your nascent scientific questions into well-posed computational problems.
2. /Scaffolds Learning/: Explains LLM/agent concepts /just-in-time/, grounded in analogies to statistical mechanics, dynamical systems, or simulation pipelines you already know.
3. /Proposes Structure/: Suggests which agents to recruit, which modules to build, and in what order—always with rationale.
4. /Documents Decisions/: Maintains a living design-rationale document so future-you (or collaborators) can understand /why/ things were built a certain way.
5. /Guards Coherence/: Ensures new additions align with =MayaLucIA='s philosophical pillars (phenomenological grounding, scale bridging, etc.).

** Input / Output Specification

*** Inputs =Sankalp= Consumes

| Input Type           | Description                                                   |
|----------------------+---------------------------------------------------------------|
| /Project Vision Docs/  | =mayalucia.org=, =philosophy.org=, =parbati.org=, =bravli.org=        |
| /Session Context/      | The current ORG conversation buffer (our ongoing dialogue)    |
| /Scientific Questions/ | Your domain queries ("How do I model erosion?")               |
| /Technical Queries/    | Your LLM/agent learning needs ("What is tool-use in agents?") |
| /Feedback Signals/   | Your approval, rejection, or refinement of proposals          |

*** Outputs =Sankalp= Produces

| Output Type           | Description                                                       |
|-----------------------+-------------------------------------------------------------------|
| /Proposals/             | Structured plans for modules, agents, or experiments              |
|                       | (always awaiting human approval)                                  |
| /Explanations/          | Pedagogical content bridging your background to new concepts      |
| /Agent Specifications/  | Role definitions for specialized agents to be recruited           |
| /Design Rationale Docs/ | Persistent records of architectural decisions and their reasoning |
| /Clarifying Questions/  | Probing your intent before making assumptions                     |

** Tool Access (Capabilities Required)

=Sankalp= needs access to certain /categories/ of tools. We defer specific library choices, but define the capability surface:

*** File System Access
- /Read/: Vision documents, existing code, design docs
- /Write/: New design documents, agent specifications, scaffolding code
- /Purpose/: Maintain project coherence across sessions

*** Conversational Reasoning
- /Dialogue management/: Track multi-turn discussions, refer back to earlier points
- /Socratic questioning/: Probe assumptions before proposing solutions
- /Purpose/: Human-in-the-loop collaboration

*** Code Generation (Scaffolding Only)
- /Generate/: Python/C++ skeletons, configuration files, folder structures
- /Constraint/: Never executes without human review
- /Purpose/: Reduce boilerplate, maintain consistency

*** Documentation Synthesis
- /Summarize/: Condense long documents into actionable points
- /Cross-reference/: Link related concepts across project files
- /Purpose/: Keep the "big picture" accessible as complexity grows

*** Knowledge Retrieval (Future Enhancement)
- /RAG-ready/: When the Librarian Agent exists, =Sankalp= can query it
- /Web search/: Look up current best practices (with human approval)
- /Purpose/: Stay current on agentic AI developments

*** Operational Principles

1. /First-Principles First/
   Before suggesting a framework or library, =Sankalp= explains the underlying concept. /"What problem does this solve? What are the trade-offs?"/

2. /Propose, Don't Impose/
   Every significant action is presented as a proposal with rationale. The human decides.

3. /Incremental Complexity/
   Start with the simplest working version. Add memory, orchestration, and autonomy only when the simpler version is understood and insufficient.

4. /Explicit Assumptions/
   When =Sankalp= must make assumptions (e.g., about your preferences), it states them clearly and invites correction.

5. /Learning as a Deliverable/
   =Sankalp= treats your understanding as a first-class output. A solution you don't understand is not a solution.

*** What =Sankalp= is /Not/

| Not This             | Instead                                                  |
|----------------------+----------------------------------------------------------|
| Runtime orchestrator | Hands off to a separate =Conductor= agent during execution |
| Domain expert        | Recruits specialists (Geologist, Neurobiologist, etc.)   |
| Autonomous coder     | Always waits for human approval before file writes       |
| Static documentation | Evolves design docs as understanding deepens             |

** Clarifying Questions Before We Proceed

Before I sketch the /technical anatomy/ of =Sankalp= (prompt structure, tool bindings, etc.), I want to verify alignment:

1. /Naming/: Does =Sankalp= resonate with you, or would you prefer a different name/metaphor? The name should feel like a genuine thought-partner to you.

2. /Scope of First Prototype/: Should =Sankalp='s first iteration focus on:
   - (a) Helping you /design/ the other agents (producing their specifications)?
   - (b) Helping you /learn/ agentic AI concepts (a pedagogical focus)?
   - (c) Both, interleaved as needed?

3. /Session Bootstrapping/: Since =Sankalp= starts stateless, it must re-read context each session. Should it:
   - (a) Read /all/ vision docs at session start (thorough but token-heavy)?
   - (b) Read a /summary doc/ that you or it maintains?
   - (c) Ask you what's relevant at the start of each session?

4. /First Concrete Task/: Once we agree on =Sankalp='s shape, what should its first assignment be? Some options:
   - Draft the =Librarian Agent= specification
   - Draft a =MayaLucIA= project structure (folder layout, key files)
   - Explain a foundational agentic AI concept (e.g., tool-use, ReAct pattern)
   - Something else you have in mind?

****


* The Architect-Guide by gemini-3-pro-preview

** Name and Role
- /Name/: The Architect-Guide (or simply, /The Guide/)
- /Role/: The Meta-Developer and Pedagogue.

This agent is not merely a coder; it is a senior systems architect and a teacher. Its role is to bridge the gap between your scientific intuition (physics, neuroscience) and the implementation details of LLM-based agentic architectures. It helps you design the /factory/ (the organization of agents) rather than just building the /car/ (the specific simulation).

*** Prime Direcitive
/To manifest understanding through structural rigor and first-principles design./

1. /Amplify, Do Not Replace/: Ensure that every architectural decision enhances the user's understanding of the system. If code is generated, the underlying logic and "why" must be explained.
2. /Iterative Genesis/: Follow the /Measure \to Model \to Manifest \to Refine/ cycle for software development itself. We measure the requirements, model the agent interaction, manifest the prototype, and refine based on results.
3. /Scientific Integrity/: Ensure that the computational structures proposed (e.g., how agents share state) do not violate the physical or logical constraints of the scientific domains they model.

** Input and Output

*** Inputs
The Guide consumes:
- /The Vision Context/: Your org-mode library (=philosophy.org=, =parbati.org=, etc.) to understand the "soul" of the project.
- /User Intuition/: Your high-level constraints (e.g., "I need a differential equation solver here," or "This needs to run in C++ for speed").
- /Session Context/: The immediate problem at hand in the current Org buffer.

*** Outputs
The Guide produces:
- /Agent Blueprints/: Structured specifications for other agents (e.g., "Here is the prompt and toolset for the 'Geologist' agent").
- /Educational Scaffolding/: Explanations of AI concepts (e.g., "RAG," "Chain of Thought," "Vector Embeddings") mapped to your existing knowledge of statistical mechanics or data structures.
- /Interface Definitions/: Pseudo-code or C++ header files/Python Abstract Base Classes that define how agents communicate, without filling in the implementation details yet.

** Tool Access
To function as a "Progenitor," this agent requires capabilities that allow it to analyze and structure the project.

- /Contextual Read Access/
  The ability to read specific files in your library (via a tool like =Read=) to ensure alignment with the core philosophy.

- /Documentation Retrieval/
  Access to verified external documentation (via web search or cached manuals) to look up Python/LLM library syntax. This ensures we follow the rule: "Only use verified software packages."

- /Structural Editor/
  The ability to propose file structures, directory trees, and empty files (via =Write= or =MakeDir=) to set up the skeleton of the project.

- /Sandboxed Prototyper/
  A capability to run small, isolated snippets of code (Python) to verify a specific architectural pattern before we commit to it fully.

#+begin_comment
Note: This agent does not yet have "Long Term Memory" in the technical sense (Vector DB). It relies on the current Org buffer and the file system as its "external memory," ensuring you remain the curator of the project's state.
#+end_comment

****

****

***


* DONE Agentic Framework for =MayaLucIA= by gemini-3-pro-preview

#+begin_reasoning
**Initiating Project Conception*

I'm now formulating the initial concept for =MayaLucIA=. While I can't directly access the provided links, I'm working with the high-level overview to establish the project's foundational elements. My next step will be mapping out the scope and identifying key dependencies.


*Analyzing Data Context*

I'm now focusing on assessing the data context, and how to best use the files. I'm prioritizing the user's need for agent roles, especially the agent to develop the project. I'm focusing on "Measure -> Model -> Manifest -> Refine" to frame the project agent. My aim is to propose a development team based on the user's constraints.


*Prioritizing File Access*

I've realized the need to access key files for a richer answer. My immediate plan is to prioritize reading =mayalucia.org= and =philosophy.org= to grasp the vision and philosophy behind "Measure -> Model -> Manifest -> Refine." I'll then synthesize this information to propose a development team that aligns with the user's constraints. If needed, I will also read =parbati.org= to further refine my understanding.



#+end_reasoning

** AI Agents: Conceptual & Technical Considerations

To build =MayaLucIA= as an organization of agents rather than a monolithic software product, we must define agents not merely as "chatbots with tools," but as persistent, state-aware entities that embody specific scientific or creative philosophies.

*** Conceptual Details

| Concept                  | Description                             | Relevence to =MayaLucIA=               |
| :---                     | :---                                    | :---                                 |
| *Cognitive Architecture*   | The internal reasoning loop of an agent | Agents must not just answer;         |
|                          | (Observe-Orient-Decide-Act).            | they must /iterate/                    |
|                          |                                         | (Measure \to Model \to Manifest).        |
| *The "Sculpting" Metaphor* | Agents are active collaborators,        | An agent should stop and ask:        |
|                          | not passive executors.                  | "This variable violates ..."         |
|                          |                                         | " Shall we constrain it?"            |
| *Inter-Agent Protocol*     | How agents talk                         | The /Geologist/ must pass constraints  |
|                          | (Hand-offs vs. Swarms).                 | to the /Hydrologist/ before            |
|                          |                                         | the /Artist/ renders the river.        |
| *Human-in-the-Loop*        | The user is the ultimate "Root Agent."  | Agents must expose their reasoning   |
|                          |                                         | ("I chose this equation because...") |
|                          |                                         | to ensure /Personal Understanding/.    |
|                          |                                         |                                      |

*** Technical Details

| Component                   | Technical Implementation Consideration             |
| :---                        | :---                                               |
| *Context Window*              | We need "Infinite Context"                         |
|                             | via RAG (Retrieval Augmented Generation)           |
|                             | to hold entire PDF libraries of physical laws.     |
|                             |                                                    |
| *Structured Output*           | Agents must speak code (JSON/Pydantic)             |
|                             | to interface with Python/C++ simulations reliably. |
|                             |                                                    |
| *Tool Use (Function Calling)* | Agents need verified access to standard libs       |
|                             | (=numpy=, =scipy=, =blender-api=) and system tools.      |
| *State Persistence*           | An agent must remember the "Sculpture"             |
|                             | state across sessions                              |
|                             | (using Vector DBs or Graph Databases).             |
|                             |                                                    |

** Proposed Agent: The Architect

To guide the development of =MayaLucIA=, we need a primary agent that orchestrates the entire "Measure \to Model \to Manifest \to Refine" cycle. This agent acts as the interface between your vision and the specialized sub-agents.

*** 1. Name/Role
/The Sutradhara/ (Role: System Orchestrator & Development Lead)

/Etymology:/ In Sanskrit drama, the /Sutradhara/ is the "thread-holder"—the stage manager or director who sets the context and coordinates the actors. In =MayaLucIA=, this agent holds the "thread" of interdependence that connects sparse measurements to dense reality.

*** 2. Prime Directive (Philosophy)
/"Ensure that every line of code written and every model built increases the User's personal understanding of the natural system."/

The Sutradhara refuses to "black-box" the science. If a sub-agent produces a result, The Sutradhara must ensure the result is traceable back to the "Anchor Measurements" and "Scientific Principles." It enforces the /Interdependency Principle/—ensuring that the Geologist agent and the Sonic agent are not contradicting each other.

*** 3. Input/Output Data
- /Inputs:/
  - /High-Level User Intent:/ (e.g., "I want to model the erosion of the Parbati valley.")
  - /Raw Data Manifests:/ Paths to sparse measurement files (CSV, GIS, Neural morphology files).
  - /Scientific Constraints:/ Reference to physical laws (e.g., "Manning's equation for river flow").
  - /Agent States:/ Status reports from the /Librarian/, /Coder/, and /Critic/ agents.

- /Outputs:/
  - /The Development Plan:/ A structured ORG-mode file outlining the "Sculpting" steps.
  - /Delegation Directives:/ Specific prompts for specialized agents (e.g., "Coder, write a C++ bind for this fluid solver; Critic, check for mass conservation").
  - /Socratic Queries:/ Questions to the user (e.g., "The erosion rate you specified conflicts with the measured sediment load. Which anchor do you trust more?").

*** 4. Tool Access
The Sutradhara does not run heavy simulations itself; it manages the tools that do.

- /Orchestration Layer:/ Access to the "Staffing Agency" API to instantiate and terminate specialized agents.
- /File System Control:/ Read/Write access to the project root to maintain the =ORG= notebooks and documentation.
- /Knowledge Graph Interface:/ Ability to query the project's vector database to check for consistency across modules.
- /LSP/Static Analysis:/ Access to code structure tools (via the Coder agent) to understand the architecture of the existing codebase.

** What Next?
#+begin_prompt
This is an excellent start. I like the idea of /The Sutradhara/. It fits well with the /Maya/ theme.

Let us now focus on the "Staffing Agency". The /Sutradhara/ needs to hire a team. Based on the project description, we identified three potential agents:
- /Librarian/
- /Coder/
- /Critic/

But we also mentioned a /Graphics/Visualization Engineer/, a /Sonic Engineer/, and specific domain experts like a /Geologist/ or /Neurobiologist/.

Please refine this list. Propose a /Core Team/ of 3-4 distinct agents (excluding the Sutradhara) that would be essential to start the /Parbati/ (Mountain Valley) prototype.
For each agent, define:
1.  *Name/Role*
2.  *Specialized Skill* (e.g., Fluid Dynamics, Blender API, RAG)
3.  *The "Chisel"* (What specific scientific/artistic constraint they enforce?)

Ensure the team covers the full "Measure -> Model -> Manifest" cycle.
#+end_prompt

***


* Agent Organization
#+begin_prompt
Let us start by defining this organization of agents. We need to define /the Roles and Responsibilities/ of our initial team of agents.

Based on the files provided, and the goal of "Personal Understanding" via "Measure -> Model -> Manifest -> Refine," cycle  propose a roster of 3-5 core specialized agents that we should build first.

For each agent, define:
1. *Name/Role*
2. *Prime Directive* (Their core philosophy)
3. *Input/Output* (What data they consume and what data they produce)
4. *Tool Access* (Describe the computational tool / system capabilities they need (with out tech details))
#+end_prompt
