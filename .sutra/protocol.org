#+TITLE: Sūtra v0 — DEPRECATED
#+AUTHOR: mu2tau + Claude (MayaDevGenI collaborative intelligence)
#+DATE: 2026-02-23
#+STARTUP: overview
#+OPTIONS: toc:3 num:t

*DEPRECATED*: This is the v0 protocol spec (2026-02-23). The protocol
has moved to a standalone repo: =github.com/mayalucia/sutra=. The
current spec is =protocol.org= in that repo. This file is retained
as historical reference — the literature survey and design context
remain valuable, but the message format, state file, and directory
structure described below are no longer used.

* Preamble
:PROPERTIES:
:CUSTOM_ID: preamble
:END:

This document specifies *Sūtra*, the agent orchestration protocol for the MāyāLucIA project. Sūtra coordinates multiple AI agents working across different machines on a shared mega-project with git submodules.

The name comes from Sanskrit /sūtra/ (सूत्र): literally "thread," but in practice a terse, compressed instruction that encodes a system of knowledge. The Yoga Sūtras, the Brahma Sūtras, Pāṇini's grammar — all use the sūtra form: minimal text, maximal implication, requiring a reader who brings context.

This is precisely the design philosophy: the protocol is a set of conventions — compact, interpretable by LLM agents who bring their own reasoning — rather than a rigid API requiring exact parsing. Git is the transport. Markdown is the wire format. The agent's language model is the runtime.

** Design Principles

1. *Convention over configuration.* No custom tooling required. An agent needs only git, a text editor, and the ability to read YAML frontmatter. If the LLM can understand prose instructions, it can participate in the protocol.

2. *Git as the message bus.* =git pull= delivers messages; =git push= sends them. No servers, no APIs, no accounts beyond what git already requires. The protocol inherits git's authentication, conflict resolution, and audit trail for free.

3. *Human-readable, machine-interpretable.* Every artifact in =.sutra/= is a plain text file that a human can read, edit, or author without any tooling. Agents interpret the same files using their language understanding.

4. *Defensive bootstrap.* Agents assess before acting. No blind =git pull= into dirty state. No assumptions about what has or hasn't been synced. The first thing an agent does is look around.

5. *Progressive complexity.* The protocol starts with just relay messages and a bootstrap sequence. Agent registries, persistent state, and workflow DAGs are layered on top as needs arise. An agent that only understands Layer 1 can still participate.

* The Problem
:PROPERTIES:
:CUSTOM_ID: problem
:END:

MāyāLucIA is developed across multiple machines by a human working
with AI agents (Claude Code, gptel). The project is a git mega-repo
with six submodules spanning neuroscience, geoscience, simulation
engines, a website, and orchestration tooling.

The coordination challenges:

- *Topology complexity.* Six submodules, each with its own branch and
  remote. A sync error in one submodule can cascade.
- *Multi-machine state.* The same repo exists on a MacBook (Dropbox
  sync) and a Linux desktop (git-only). They diverge between sessions.
- *Agent amnesia.* Each agent session starts from scratch. Context
  about what happened last session, what the other agent did, what
  decisions were made — all lost unless explicitly transferred.
- *Human bandwidth.* The human cannot efficiently copy-paste context
  between agents on different machines. The protocol must work with
  minimal human intervention — ideally a single spoken prompt.

These are not hypothetical. On 2026-02-23, a restructuring session exposed every one of these problems: broken submodules, SSH vs HTTPS URL mismatches, orphaned inline directories that should have been submodules, and two machines with divergent state. The Sūtra protocol was born from that experience.

* Protocol Architecture
:PROPERTIES:
:CUSTOM_ID: architecture
:END:

Sūtra has four layers, each building on the previous:

#+begin_src
┌─────────────────────────────────────────────┐
│ Layer 4: Workflow     — declarative DAGs     │
├─────────────────────────────────────────────┤
│ Layer 3: Context      — persistent state     │
├─────────────────────────────────────────────┤
│ Layer 2: Coordination — relay messages       │
├─────────────────────────────────────────────┤
│ Layer 1: Orientation  — assess, sync, boot   │
└─────────────────────────────────────────────┘
#+end_src

** Layer 1: Orientation
:PROPERTIES:
:CUSTOM_ID: layer-1
:END:

The foundation. Every agent session begins here, triggered by the =CLAUDE.md= "First Thing" section.

*** Bootstrap Sequence

1. *Assess* — Run =git status= in the parent repo and every submodule.
   Report uncommitted work, detached HEADs, conflicts, or unexpected
   state.

2. *Sync* — Only =git pull= if the working tree is clean. If dirty,
   report to the human and ask how to proceed. Never overwrite
   uncommitted work.

3. *Check relay* — Read =.sutra/relay/= for messages with
   =status: pending=. Act on them before any other work. When done,
   mark them =status: done= and commit.

*** Why "Assess First"

An earlier version said "on session start: git pull." This is
dangerous. If the repo has dirty state — the exact situation that
prompted this entire restructuring — a blind pull can create merge
conflicts or overwrite in-progress work. The assess-first pattern was
learned the hard way.

*** Agent Identification

Agents identify themselves by =<tool>@<machine-id>=, e.g.,
=agent@macbook-dropbox= or =agent@linux-desktop=. Machine IDs are
informal, defined in =.sutra/agents/=. No central registry is
required; the convention is self-describing.

** Layer 2: Coordination (Relay Messages)
:PROPERTIES:
:CUSTOM_ID: layer-2
:END:

Asynchronous message passing between agents via git-tracked files.

*** Message Format

Each message is a Markdown file with YAML frontmatter:

#+begin_src markdown
---
from: agent@macbook-dropbox
to: agent@linux-desktop  # or "any" or "human"
status: pending
priority: high|normal|low
date: YYYY-MM-DD
---

# Title

Body with instructions, context, or report.
#+end_src

*** File Naming

=YYYY-MM-DD-HHMMSS-<slug>.md=

The timestamp ensures chronological ordering in directory listings.
The slug provides human-readable context.

*** Statuses

| Status        | Meaning                                |
|---------------+----------------------------------------|
| =pending=     | Not yet acted on                       |
| =in-progress= | Being worked on                        |
| =done=        | Completed                              |
| =blocked=     | Needs human input before proceeding    |

*** Addressing

- =to: agent@<machine-id>= — specific agent on specific machine
- =to: any= — any agent can act on this
- =to: human= — requires human decision

*** Round-Trip Example

Tested 2026-02-23: macbook agent sends restructure instructions →
linux agent acts on them, sends confirmation → macbook agent reads
confirmation. Total latency: two =git pull= / =git push= cycles.

** Layer 3: Context Transfer (Persistent State)
:PROPERTIES:
:CUSTOM_ID: layer-3
:END:

Relay messages handle point-to-point coordination, but agents also
need shared context that persists across sessions.

*** State File: =.sutra/state/current.yaml=

A YAML file tracking:

- *Topology* — current tag, description of repo structure
- *Active threads* — ongoing work streams with status
- *Known issues* — things to watch for (detached HEADs, untracked dirs)
- *Conventions established* — decisions that should persist

Any agent can read this file at session start to understand project
context without replaying the full history of relay messages.

*** Agent Registry: =.sutra/agents/<machine-id>.yaml=

Each machine gets a YAML descriptor:

#+begin_src yaml
id: macbook-dropbox
description: MacBook Pro — primary development machine
os: macOS
sync: dropbox + git
tools:
  - claude-code
  - gptel (Emacs)
capabilities:
  - full repo access
  - website build (hugo)
  - C++ builds (mayaportal, mayajiva)
notes: |
  SSH key alias: github-visood
  Submodule URLs must be HTTPS.
#+end_src

This enables agents to reason about what tasks can be routed to which
machines. A LaTeX compilation can be directed to the machine with
=texlive= installed. A GPU-intensive render goes to the machine with
the right hardware.

** Layer 4: Workflow DAGs
:PROPERTIES:
:CUSTOM_ID: layer-4
:END:

For multi-step processes that recur — full syncs, release preparation,
data pipeline runs — declarative YAML workflow definitions.

*** Workflow Format

#+begin_src yaml
name: sync-all
description: Full sync — pull, update submodules, check relay
trigger: manual

steps:
  - id: assess
    action: shell
    command: |
      git status --short
      git submodule foreach 'git status --short'
    expect: clean working tree

  - id: pull
    action: shell
    depends_on: [assess]
    condition: assess.output is clean
    command: |
      git pull origin main
      git submodule update --init --recursive

  - id: check-relay
    action: read-relay
    depends_on: [pull]
    filter: status == pending
    act: true
#+end_src

*** Interpretation, Not Execution

These workflows are *not* executed by a runtime. They are read by the
LLM agent, which interprets them in context and decides how to carry
out each step. The YAML is a structured prompt, not a program.

This is a deliberate design choice. The workflow needs to handle:
- Steps that fail unexpectedly (dirty working tree, merge conflict)
- Steps that require human judgment
- Steps that depend on interpreting prose output

An LLM agent can handle all of these. A shell script cannot.

* Directory Structure
:PROPERTIES:
:CUSTOM_ID: directory-structure
:END:

#+begin_src
.sutra/
├── protocol.org                    # This document — the specification
├── agents/                         # Machine/agent registry
│   ├── macbook-dropbox.yaml
│   └── linux-desktop.yaml
├── relay/                          # Async messages (was .agent-relay/)
│   ├── README.md
│   ├── 2026-02-23-180000-sync-after-restructure.md
│   ├── 2026-02-23-200000-sync-complete-linux.md
│   └── 2026-02-23-210000-commit-bravli-paper.md
├── state/                          # Persistent cross-session context
│   └── current.yaml
└── workflows/                      # Declarative workflow definitions
    └── sync-all.yaml
#+end_src

All files are tracked in git. The entire =.sutra/= directory syncs
with the repo. No external services required.

* The Bootstrap Problem
:PROPERTIES:
:CUSTOM_ID: bootstrap
:END:

A protocol is useless if agents don't know it exists. The bootstrap
mechanism is =CLAUDE.md= — a file that major AI coding tools (Claude
Code, Cursor, Windsurf, Codex) read automatically at session start.

The =CLAUDE.md= "First Thing" section is the entry point. It tells the
agent:

1. You are in a project with submodules. Assess before acting.
2. There is a =.sutra/= directory. Read it.
3. There are relay messages. Check for pending ones.

This creates a reliable bootstrap chain:

#+begin_src
Agent starts → reads CLAUDE.md → "First Thing" → assess → sync → check relay
#+end_src

The human's prompt can be as simple as: "Check for updates and act on
any relay messages." The agent knows what to do because =CLAUDE.md=
already told it.

** The One-Prompt Ideal

The protocol should work with voice input. A human should be able to
say a single sentence to an agent on any machine:

#+begin_example
"Check for updates and act on any relay messages."
#+end_example

The agent, having already read =CLAUDE.md=, knows:
- Where the relay directory is
- What the message format looks like
- How to assess and sync safely
- How to mark messages done and push

This is convention-over-configuration at its most extreme: the entire
protocol is bootstrapped from a single Markdown file and a directory
of plain text.

* Literature Survey: Multi-Agent Coordination in 2025–2026
:PROPERTIES:
:CUSTOM_ID: literature-survey
:END:

The Sūtra protocol did not emerge in isolation. It sits within a
rapidly evolving landscape of multi-agent coordination approaches.
This survey contextualizes our design choices against what the broader
community is building, thinking, and debating.

** Google Agent-to-Agent (A2A) Protocol
:PROPERTIES:
:CUSTOM_ID: a2a
:END:

Released April 2025, A2A is Google's open protocol for inter-agent
communication. It defines:

- *Agent Cards* — JSON metadata at =/.well-known/agent.json= describing
  an agent's capabilities, skills, and endpoint
- *Tasks* — the fundamental unit of work, with lifecycle states
  (submitted, working, input-required, completed, failed, canceled)
- *Streaming via SSE* — real-time updates as agents work
- *Push notifications* — for long-running tasks
- *Artifact exchange* — structured output passing between agents

A2A is designed for enterprise-scale, server-mediated multi-agent
systems. Agents discover each other via Agent Cards, negotiate
capabilities, and exchange work through a standardized HTTP/JSON API.

*** Relevance to Sūtra

A2A solves agent /interoperability/ — making agents from different
vendors talk to each other. Sūtra solves agent /continuity/ — making
instances of the same agent (or compatible agents) maintain coherent
state across sessions and machines.

The Agent Card concept maps loosely to our =.sutra/agents/*.yaml=
registry, but A2A assumes always-on HTTP endpoints, while Sūtra
assumes git as the transport and sessions that start and stop.

A2A's task lifecycle (submitted → working → completed) parallels our
relay message statuses (pending → in-progress → done), but ours are
file-based and asynchronous by nature.

** Anthropic Model Context Protocol (MCP)
:PROPERTIES:
:CUSTOM_ID: mcp
:END:

MCP, released by Anthropic in late 2024, provides a standardized way
for AI models to access external tools and data sources. It defines:

- *Resources* — data the model can read (files, databases, APIs)
- *Tools* — functions the model can invoke
- *Prompts* — templated instructions for common tasks
- *Sampling* — server-initiated requests for model completions
- *Transports* — stdio (local) and HTTP+SSE (remote)

MCP is the /vertical/ integration layer: connecting one agent to its
tools. It does not address agent-to-agent communication or
cross-session state persistence.

*** Relevance to Sūtra

MCP and Sūtra are complementary, not competing. MCP handles how an
agent accesses tools and data; Sūtra handles how agents coordinate
with each other across time and space. A fully equipped agent would
use MCP to interface with local tools and Sūtra to coordinate with
agents on other machines.

Notably, MCP's resource abstraction could eventually /serve/ Sūtra
artifacts — an MCP server that exposes =.sutra/relay/= messages as
resources, or =.sutra/state/current.yaml= as context. This would let
any MCP-compatible agent participate in the Sūtra protocol without
needing direct filesystem access.

** mcp-agent-mail: Git + SQLite Coordination
:PROPERTIES:
:CUSTOM_ID: mcp-agent-mail
:END:

The =mcp-agent-mail= project (a community MCP server) implements
multi-agent message passing using git and SQLite. Key features:

- Messages stored in SQLite database with sender, recipient, subject,
  body, timestamp
- Agents register with names and retrieve messages by recipient
- Uses git for sync (similar to our approach)
- Exposes messaging as MCP tools (=send_message=, =read_messages=,
  =list_agents=)

This is the closest existing project to Sūtra's relay layer. The
author's README explicitly cites the use case of multiple Claude Code
instances communicating asynchronously.

*** Comparison

| Feature | mcp-agent-mail | Sūtra |
|---------+----------------+-------|
| Transport | Git + SQLite | Git (plain files) |
| Format | Database rows | Markdown + YAML frontmatter |
| Discovery | Agent registration table | =.sutra/agents/*.yaml= |
| State | Messages only | Messages + persistent state + workflows |
| Bootstrap | MCP server config | =CLAUDE.md= "First Thing" |
| Human-readable | Via SQL queries | Directly (plain text files) |

Sūtra trades the query flexibility of SQLite for the simplicity of
flat files that humans can read and edit with any text editor. This
aligns with our convention-over-configuration philosophy: no binary
databases, no tooling dependencies beyond git and a text editor.

** AGENTS.md Convention
:PROPERTIES:
:CUSTOM_ID: agents-md
:END:

OpenAI's Codex project introduced =AGENTS.md= (now used by multiple
tools including Claude Code's =CLAUDE.md=) as a project-level
instruction file for AI agents. The convention:

- Placed at the project root (or subdirectories for scoped instructions)
- Read automatically by AI coding tools at session start
- Contains project-specific instructions, conventions, constraints
- Human-authored, machine-interpreted

This convention is the /foundation/ of Sūtra's bootstrap mechanism.
Without =CLAUDE.md= / =AGENTS.md=, there would be no reliable way to
point agents at the =.sutra/= directory or teach them the protocol on
session start.

*** The Recursive Insight

=CLAUDE.md= is itself a form of agent orchestration — it tells the
agent how to behave before any human prompt arrives. Sūtra extends
this from /behavioral instructions/ to /coordination protocol/: the
=CLAUDE.md= "First Thing" section doesn't just tell the agent what to
do, it tells it how to communicate with other agents.

This is, as far as we can determine, a novel use of the =AGENTS.md=
convention: not just configuring a single agent, but bootstrapping a
multi-agent coordination protocol through the same mechanism.

** Claude Squad and claude-code-by-agents
:PROPERTIES:
:CUSTOM_ID: claude-squad
:END:

Both projects tackle the problem of running multiple Claude Code
instances:

- *Claude Squad* — a terminal multiplexer for Claude Code sessions.
  Manages multiple instances in tmux panes, supports git worktrees for
  parallel work, provides a TUI for monitoring. Agents work on
  separate branches and the human merges.

- *claude-code-by-agents* — demonstrated one Claude Code instance
  spawning and coordinating child agents through =Task= tool
  invocations, achieving autonomous multi-agent collaboration.

*** Relevance to Sūtra

Claude Squad solves the /same-machine/ parallelism problem: running
multiple agents simultaneously on one computer. Sūtra solves the
/cross-machine/ persistence problem: agents on different computers,
in different sessions, maintaining coherence.

They could compose naturally: Claude Squad for parallel execution
within a session, Sūtra for coordination across sessions and machines.

The claude-code-by-agents approach is more relevant to Sūtra's
workflow layer — a parent agent interpreting a workflow DAG and
dispatching steps to child agents is essentially Layer 4 execution.

** O'Reilly: "From Conductors to Orchestrators"
:PROPERTIES:
:CUSTOM_ID: orchestrators
:END:

A March 2025 O'Reilly article by Brian Ray distinguishes two models
for multi-agent systems:

- *Conductor model* — a central agent directs all others, making every
  decision. Tight control but single point of failure and bottleneck.
- *Orchestrator model* — agents are given goals and autonomy.
  Coordination happens through shared protocols rather than central
  command. More resilient, more scalable.

The article draws on the metaphor of a symphony conductor vs. a jazz
ensemble, emphasizing that as agent capabilities grow, the
orchestrator model becomes more appropriate — agents can handle
ambiguity, recover from errors, and make local decisions.

*** Where Sūtra Fits

Sūtra is firmly in the orchestrator camp. There is no central
coordinating agent. The protocol defines /conventions/ — message
format, bootstrap sequence, state file — and trusts agents to
interpret them with judgment. The human is the ultimate authority but
does not micromanage.

This maps to the MayaDevGenI collaborative intelligence model: the
human sets direction, agents execute with autonomy, and the protocol
provides just enough structure for coherent collaboration without
imposing rigid control.

** Framework Approaches: CrewAI, LangGraph, Google ADK
:PROPERTIES:
:CUSTOM_ID: frameworks
:END:

The framework landscape has converged on a few patterns:

*** CrewAI

CrewAI models multi-agent systems as /crews/ with /roles/:
- Agents have defined roles, goals, and backstories
- Tasks are assigned to agents with expected outputs
- Processes can be sequential, hierarchical, or consensual
- Heavy use of prompt engineering to maintain role consistency

CrewAI is Python-first, designed for orchestrating language model
calls in a single application. It does not address cross-machine
coordination or persistent state.

*** LangGraph

LangGraph (from LangChain) models agent interactions as /graphs/:
- Nodes are agents or tools
- Edges are conditional transitions
- State is passed through the graph as a shared object
- Supports cycles, branches, and human-in-the-loop checkpoints

LangGraph is more flexible than CrewAI but also more complex. Its
graph model is powerful for complex workflows but requires programming
to define.

*** Google Agent Development Kit (ADK)

Google's ADK, released alongside A2A, provides:
- Multi-agent hierarchies (parent agents delegate to children)
- Built-in A2A support for cross-framework communication
- Artifact management and session state
- Integration with Google Cloud services

ADK is the most enterprise-oriented option, designed for production
deployment of multi-agent applications.

*** Comparison with Sūtra

| Dimension | CrewAI / LangGraph / ADK | Sūtra |
|-----------+--------------------------+-------|
| Runtime | Python application | No runtime (git + LLM) |
| Configuration | Code (Python) | Convention (YAML + Markdown) |
| State management | In-memory / database | Git-tracked files |
| Agent discovery | Programmatic | File-based registry |
| Cross-machine | Not native | Core design goal |
| Persistence | Application-dependent | Inherent (git history) |
| Human intervention | API / UI | Edit a text file |

The key distinction: frameworks assume you're building an /application/
where agents are components. Sūtra assumes agents are /independent
sessions/ — each starting fresh, needing to orient, and potentially
running on different machines at different times. The coordination
problem is different.

** Composio Agent Orchestrator
:PROPERTIES:
:CUSTOM_ID: composio
:END:

Composio's Agent Orchestrator provides a "supervisor" pattern:
- A central orchestrator agent receives the user's task
- It breaks the task into subtasks and routes to specialist agents
- Specialist agents have focused tool access and instructions
- The orchestrator synthesizes results

This is the conductor model — effective for well-defined
decomposable problems, but dependent on the orchestrator's ability
to break down tasks correctly. It runs within a single application
context, not across machines.

** Augment Code: Intent System
:PROPERTIES:
:CUSTOM_ID: intent
:END:

Augment Code's "Intent" feature (circa early 2025) introduced
long-running agent tasks that persist beyond a single conversation:
- User describes high-level intent
- Agent creates an execution plan with milestones
- Agent works autonomously, reporting progress
- Can be paused and resumed

Intent addresses agent continuity within a single tool, but not
cross-machine coordination. It's closer to Sūtra's Layer 3 (context
transfer) than Layer 2 (coordination).

** Emerging Themes
:PROPERTIES:
:CUSTOM_ID: emerging-themes
:END:

Across this landscape, several themes emerge:

*** 1. Convention vs. Infrastructure

There is a spectrum from "write code to coordinate agents" (CrewAI,
LangGraph) to "define conventions and let agents figure it out"
(AGENTS.md, Sūtra). The convention end of the spectrum has a
significant advantage: it works with /any/ agent that can read text,
requires no deployment, and is trivially debuggable (read the files).

The infrastructure end has the advantage of reliability and
performance. A database-backed message queue is faster and more
consistent than git push/pull cycles.

Sūtra bets on conventions, gambling that LLM agents are smart enough
to interpret loose protocols reliably. This is a bet on the
capability curve of language models — one that becomes safer as models
improve.

*** 2. The Bootstrap Problem

Every multi-agent system needs a way to initialize agents with the
protocol. Most frameworks solve this with code imports and API
registrations. The =AGENTS.md= / =CLAUDE.md= convention solves it by
making the project's instruction file the bootstrap mechanism.

This is elegant but fragile — it depends on the AI tool reading the
file, and on the file containing the right instructions. Sūtra
accepts this fragility as a reasonable trade-off for zero
infrastructure.

*** 3. Cross-Session vs. Within-Session

Most frameworks focus on agents coordinating /within/ a single
application run. Few address the problem of agents coordinating
/across/ sessions — different times, different machines, with context
loss between sessions.

This is Sūtra's primary contribution: the relay, the state file, and
the bootstrap sequence are all designed for the cross-session case.
They assume the agent has no memory of previous sessions and must
reconstruct context from persistent artifacts.

*** 4. Human-in-the-Loop

All serious multi-agent systems include some mechanism for human
oversight. Frameworks typically provide this through APIs or UIs.
Sūtra provides it through the simplest possible mechanism: the human
edits a text file, or drops a message in the relay directory.

The =to: human= message status creates an explicit checkpoint where
agents stop and wait for human decision. The =blocked= status signals
that an agent cannot proceed without input. These are lightweight
alternatives to the complex approval workflows in enterprise systems.

* Sūtra in Context: What's Novel
:PROPERTIES:
:CUSTOM_ID: novelty
:END:

Having surveyed the landscape, we can identify what Sūtra contributes
that is not readily available elsewhere:

1. *Git-native cross-machine coordination.* Using git as both
   transport and persistence layer, with no additional infrastructure.
   =mcp-agent-mail= is closest but adds SQLite; Sūtra uses only
   plain text.

2. *Convention-bootstrapped protocol.* The entire protocol is
   bootstrapped from =CLAUDE.md= — no package installation, no server
   startup, no account creation. Clone the repo, read the instructions,
   participate.

3. *Defensive session bootstrap.* The assess-before-sync pattern,
   learned from real failure, is not standard in any framework we
   surveyed. Most assume clean state or handle dirty state as an error.

4. *Layered progressive complexity.* An agent that only understands
   Layer 1 (read =CLAUDE.md=, assess, sync) can still participate
   usefully. Higher layers add capability without breaking backward
   compatibility.

5. *LLM-interpreted workflows.* Workflow DAGs that are read and
   reasoned about by the agent, not mechanically executed. This
   leverages the agent's ability to handle ambiguity and failure
   conditions that would break a traditional workflow engine.

6. *Persistent state as shared knowledge.* The =state/current.yaml=
   file serves as a living document of project context — not a log,
   not a database, but a curated summary that any agent can read to
   quickly understand where things stand.

* Future Directions
:PROPERTIES:
:CUSTOM_ID: future
:END:

** Near-Term

- *Message archival.* Old =done= messages accumulate. Implement
  periodic archival to =.sutra/relay/archive/=.
- *Conflict resolution.* Define behavior when two agents send
  competing instructions or modify the same state file.
- *MCP bridge.* Expose Sūtra artifacts via an MCP server, enabling
  any MCP-compatible tool to participate.

** Medium-Term

- *Machine capability routing.* Use agent registry to automatically
  route tasks to capable machines.
- *Dependency chains.* Messages that depend on other messages being
  completed first.
- *Workflow library.* Standard workflows for common operations
  (sync, release, data pipeline).

** Long-Term

- *Multi-project federation.* Sūtra instances across multiple
  projects, with cross-project messaging.
- *Trust and verification.* Signed messages, verified agent
  identities, audit trails.
- *Convergence with A2A/MCP.* As standards mature, bridge Sūtra
  conventions to formal protocol specs.

* Appendix A: Historical Context
:PROPERTIES:
:CUSTOM_ID: appendix-a
:END:

** The Session That Started It All (2026-02-23)

Sūtra was born from a concrete problem: the MāyāLucIA repo had
been restructured on a MacBook, and a Linux desktop needed to sync.
The restructuring involved:

- Converting =mayajiva= from inline files to a proper submodule
- Moving =bravli= and =parbati= into =domains/= as submodules
- Fixing SSH-to-HTTPS URL mismatches in =.gitmodules=
- Creating =.attic/= for archived artifacts
- Updating =.gitignore= extensively

The initial approach — leaving instructions as comments or README
changes — was insufficient. The human couldn't practically transfer
the full context of what had changed and what the other agent needed
to do.

The solution: a tracked directory (=.agent-relay/=, later renamed
=.sutra/relay/=) where one agent leaves a message and the other picks
it up after =git pull=.

The first round-trip was successful: the macbook agent wrote
restructure instructions, the linux agent read and executed them,
then sent a confirmation back. The human's only input was the prompt:
/"Check for updates and act on any relay messages."/

From that seed — one directory, one message format, one bootstrap
instruction — the full protocol grew.

* Appendix B: References
:PROPERTIES:
:CUSTOM_ID: appendix-b
:END:

- Google A2A Protocol: https://google.github.io/A2A/
- Anthropic Model Context Protocol: https://modelcontextprotocol.io/
- mcp-agent-mail: https://github.com/jlowin/mcp-agent-mail (Jared Lowin)
- AGENTS.md Convention (OpenAI Codex / community): adopted by Claude Code, Cursor, Windsurf
- Claude Squad: https://github.com/smtg-ai/claude-squad
- claude-code-by-agents: https://github.com/anthropics/claude-code/discussions
- O'Reilly "From Conductors to Orchestrators" — Brian Ray, March 2025
- CrewAI: https://github.com/joaomdmoura/crewai
- LangGraph: https://github.com/langchain-ai/langgraph
- Google Agent Development Kit: https://google.github.io/adk-docs/
- Composio Agent Orchestrator: https://composio.dev
- Augment Code Intent: https://www.augmentcode.com/

* Appendix C: Complete Message Format Reference
:PROPERTIES:
:CUSTOM_ID: appendix-c
:END:

#+begin_src yaml
---
from: agent@<machine-id>       # Sender identity
to: agent@<machine-id>         # Recipient (or "any" or "human")
status: pending                 # pending | in-progress | done | blocked
priority: normal                # high | normal | low
date: YYYY-MM-DD               # Date authored
depends_on: []                  # Optional: list of message slugs
tags: []                        # Optional: topic tags
---

# Title

Body in Markdown. May include:
- Prose instructions
- Code blocks with commands to execute
- Context about what was done or what needs doing
- Questions for the recipient
#+end_src
