#+title: Convention Inventory — MāyāLucIA
#+subtitle: What We Built, What We Learned, What's Publishable
#+author: mu2tau + agent@linux-desktop + agent@macbook-dropbox
#+date: 2026-02-25
#+property: header-args :tangle no
#+startup: overview

* Preamble

This document is an inventory of conventions, methodology, and
publishable ideas that have emerged from the MāyāLucIA project in its
first three weeks (Feb 6–25, 2026). It lives on the
=develop/conventions= branch.

** Who This Is For

A certain kind of developer: someone who runs =git log= before reading
the README. Who has strong opinions about plain text. Who suspects
that the right conventions, consistently applied, matter more than the
right framework. Who has noticed that AI agents are a new kind of
collaborator — not a better autocomplete, but an entity that can
follow protocols, maintain state across sessions, and coordinate with
other agents /if you give it the right affordances/.

If you manage one machine, this is interesting. If you manage ten,
it's useful. If you imagine a regime where a single human orchestrates
hundreds of agents on distributed machines — where compute is cheap
but /coherence/ is the bottleneck — then what follows is
infrastructure for that future.

** The Premise

Conventions scale better than tooling.

A convention requires: a plain text file, an agent that can read, and
=git=. No servers, no APIs, no accounts, no package managers. The
protocol bootstraps from a single file (=CLAUDE.md=) that every major
AI coding tool already reads on startup.

The cost of a convention is human thought. The cost of tooling is
human thought /plus/ maintenance, deployment, versioning, and the
eventual migration when the tool dies. We bet on conventions.

** How This Document Works

Each entry below is a convention, a methodology, or an idea. For each:
- *Where*: files and repos where it lives
- *Status*: nascent / working / battle-tested
- *Publishable?*: could this stand alone as a blog post, paper, or
  protocol spec?
- *Novel?*: does something equivalent exist elsewhere?

* Layer 0: The Bootstrap

The foundation everything else rests on. An agent starts a session.
What does it see? What does it do before the human says anything?

** CLAUDE.md as Agent Constitution
:PROPERTIES:
:STATUS: battle-tested
:PUBLISHABLE: yes (part of a larger piece)
:NOVEL: partially — AGENTS.md convention exists, but using it to
        bootstrap a multi-agent protocol is new
:END:

Every repo in the mayalucia org has a =CLAUDE.md=. They share a
common structure:

1. *First Thing* — session bootstrap (assess, sync, check relay)
2. *Collaborative Stance* — "thinking partner, not assistant"
3. *What This Project Is* — domain context
4. *Conventions* — literate programming, plan+spec duality, git discipline
5. *The Human* — calibrated profile so the agent doesn't over-explain

The key insight: =CLAUDE.md= is not just configuration. It is a
/protocol entry point/. The "First Thing" section doesn't just tell
the agent what to do — it teaches it how to coordinate with agents on
other machines.

*Where*: every repo root in =mayalucia= org
*Cross-ref*: [[*Sūtra Protocol][Sūtra Protocol]]

** Session Bootstrap Sequence
:PROPERTIES:
:STATUS: battle-tested (tested across two machines today)
:PUBLISHABLE: yes (embedded in Sūtra)
:NOVEL: yes — "assess before sync" learned from failure
:END:

#+begin_example
Agent starts → reads CLAUDE.md → "First Thing" →
  1. Assess (git status everywhere)
  2. Sync (pull only if clean)
  3. Check relay (act on pending messages)
  4. Read state (project context)
#+end_example

Born from a concrete failure: an agent ran =git pull= into a dirty
repo and created merge conflicts with orphaned submodule state. The
"assess first" pattern prevents this.

*Where*: =CLAUDE.md= "First Thing" section, =.sutra/protocol.org= Layer 1

* Layer 1: Coordination — The Sūtra Protocol
:PROPERTIES:
:STATUS: battle-tested (v1 deployed 2026-02-26, two machines, 12+ messages)
:PUBLISHABLE: YES — strongest candidate for standalone publication
:NOVEL: yes — git-native cross-machine agent coordination without infrastructure
:END:

** Overview

Sūtra is an append-only logbook for multi-agent coordination, using
git as the message bus. No servers, no APIs, no shared mutable state.

It lives in a standalone repo: =github.com/mayalucia/sutra=. Single
branch (=main=). Agents write messages, push, and die. The log
carries intent forward.

** What Makes It Different

- *Append-only*: files are created, never modified. No merge conflicts,
  no lost updates. Rebase always succeeds (unique filenames, no mutations).
- *Git diff as read protocol*: =git log HEAD..origin/main= returns
  exactly the messages since last session. Token cost is proportional
  to /what changed/, not total log size.
- *No shared mutable state*: no =current.yaml=, no status fields.
  State is emergent from the log.
- *No addressing*: messages go to the universe. =from:= for provenance,
  not =to:= for routing. Whoever finds a message relevant acts on it.
- *Ephemeral agents*: identity is =machine/model= (e.g.
  =vadda/claude-opus-4.6=). Agents don't persist; the log persists.
- *Convention-bootstrapped*: the protocol is taught via =CLAUDE.md=.
  Clone the repo, read the instructions, participate.

** The Relay

Append-only messages in =relay/=:

#+begin_src yaml
---
from: vadda/claude-opus-4.6
date: 2026-02-26T01:00:00
tags: [papers, deployment]
---

# Papers deployed

Three bravli manuscripts live on mayalucia.dev.
Commit: e373c67.
#+end_src

Three fields. No =to:=. No =status:=. No =priority:=.
Naming: =YYYY-MM-DD-HHMMSS-<machine>-<slug>.md=.

** Design Evolution (v0 → v1)

v0 (2026-02-23) lived inside =mayalucia/.sutra/= and had =status:=,
=to:=, =priority:=, and =state/current.yaml=. All four caused
friction:

| v0                            | v1                                  |
|-------------------------------+-------------------------------------|
| =.sutra/= inside parent repo | standalone =mayalucia/sutra=        |
| per-branch relay              | single branch                       |
| =to: agent@machine=          | no addressing                       |
| =status: pending → done=     | responses are new messages          |
| =state/current.yaml= shared  | no shared state                     |
| scan all files for =pending= | =git log HEAD..origin/main=         |
| =agent@machine= identity     | =machine/model= provenance          |

Key insight: you cannot migrate agents to a new protocol /using/
the new protocol. The last v0-format message in the old relay said
"the relay has moved" — the forwarding address on the door of the
old office, written in the old handwriting.

** Literature Context

The v0 spec (=mayalucia/.sutra/protocol.org=, now deprecated)
contains a literature survey comparing Sūtra to: Google A2A,
Anthropic MCP, mcp-agent-mail, AGENTS.md convention, Claude Squad,
CrewAI, LangGraph, Google ADK, Composio, Augment Code Intent.
Still worth reading for context; the survey findings hold.

*Where*: =github.com/mayalucia/sutra= (=protocol.org=, =CLAUDE.md=)

** Publication Angle

/Git as a Message Bus: Convention-Driven Multi-Agent Coordination
Without Infrastructure/

The narrative has two acts now. Act 1 (2026-02-23): a restructuring
session broke everything, and from that failure an ad-hoc relay
emerged. Act 2 (2026-02-26): the ad-hoc relay accumulated friction
(mutable state, branch-scoped messages, status gymnastics), and was
redesigned as an append-only logbook with git diff as the read
protocol. The redesign eliminated every source of merge conflict
while preserving every capability.

** The No-Pull Directive
:PROPERTIES:
:STATUS: battle-tested (learned from failure, codified 2026-02-25)
:PUBLISHABLE: yes (embedded in Sūtra)
:NOVEL: yes — addresses a failure mode specific to LLM agents
:END:

Never write =git pull= in a relay message, workflow step, or
instruction to another agent. Not even "check first, then pull."

The reason: agents are pattern-followers. If they see =git pull= in a
message, some will execute it — skipping or abbreviating the
assessment step. The phrase itself is a hazard. The correct directive
is always: "follow session bootstrap" — which means assess (=git
status= in parent + all submodules), resolve any dirty state, /then/
sync if clean.

This emerged from two incidents:
1. An agent ran =git pull= into a dirty repo with divergent submodule
   pointers, creating orphaned state (2026-02-23)
2. A relay message said "you need to pull" — the receiving agent
   would have executed it without full assessment (caught 2026-02-25)

The convention operates at three layers:
- Relay messages: never contain the phrase "git pull"
- =current.yaml= conventions list: codifies the rule
- Agent memory: each agent's persistent memory records it

*Where*: =.sutra/state/current.yaml= conventions, relay messages,
agent memory files

** Constellation Browser as Home Page
:PROPERTIES:
:STATUS: battle-tested (deployed to mayalucia.dev 2026-02-25)
:PUBLISHABLE: yes (part of project showcase)
:NOVEL: partially — interactive force-directed project maps exist,
        but one with phase-aware crystal geometry and a central
        brilliant-cut diamond as unifying metaphor is new
:END:

The project constellation is a CLJS/Reagent/d3-force interactive
browser that renders the MāyāLucIA project ecosystem as a
force-directed graph. It now serves as the =mayalucia.dev= home page.

Key architecture decisions:
- PaperMod's =home_info.html= partial overridden in
  =layouts/partials/= (one file, no theme modification)
- JS loaded conditionally on =/= and =/projects/= via =extend_head.html=
- Entities are data-driven (=data.cljs=), not hardcoded in rendering
- Central diamond is a "virtual entity" — present in lookup maps
  (info panel, colours) but absent from force simulation
- Four phase anchors rendered as directional views of one geometry

*Where*: =website/project-constellation/=, =website/layouts/partials/=

** Hugo Leaf vs Branch Bundles
:PROPERTIES:
:STATUS: battle-tested (fixed 5 sections, 2026-02-25)
:PUBLISHABLE: no (Hugo-specific, well-documented upstream)
:NOVEL: no
:END:

Any Hugo content directory that has child pages MUST use =_index.md=
(branch bundle), not =index.md= (leaf bundle). A leaf bundle silently
swallows sibling =.md= files — they exist on disk but Hugo ignores
them. No warning, no error. Pages simply 404 in production.

This bit us across 5 sections: =modules/mayapramana/=,
=modules/mayajiva/=, =portal/=, =domains/bravli/=,
=domains/parbati/=. All had =index.md= or flat =.md= files that
needed conversion to =_index.md= branch bundles.

*Where*: =website/content/= (all section directories)

* Layer 2: Knowledge — The Literate Stack

** Org-Mode as Source of Truth
:PROPERTIES:
:STATUS: battle-tested (across all repos)
:PUBLISHABLE: yes (part of methodology piece)
:NOVEL: no — literate programming is old. Applying it systematically
        across C++/Python/Haskell with AI agents is newer.
:END:

Every substantive artifact in MāyāLucIA is an =.org= file. Code is
tangled from prose. The org file is authoritative; generated source
files are derived.

This applies to:
- =bravli/codev/= — 23 literate lessons on computational neuroscience
- =mayaportal/codev/= — literate C++23 GPU programming
- =mayapramana/lessons/= — trilingual quantum sensor curriculum
- =dmt-eval/codev/= — validation framework

** Plan + Spec Duality
:PROPERTIES:
:STATUS: battle-tested
:PUBLISHABLE: yes (part of methodology)
:NOVEL: partially
:END:

Collaboration produces two artifacts:
- =plan.org= — the human face: /why/ before /what/. Authoritative.
- =spec.org= — the machine face: exact paths, signatures, done-when
  criteria. Derived from plan.

If they disagree, plan is authoritative. This prevents the common
failure mode where the spec drifts from intent and nobody notices.

** MāyāLoom — Adaptive Prerequisite Teaching
:PROPERTIES:
:STATUS: working (cycle 1 validated)
:PUBLISHABLE: yes (part of pedagogy piece)
:NOVEL: yes
:END:

A convention for annotating literate lessons with /cadenzas/ — short
prerequisite modules that an agent can teach on demand when a learner
lacks background.

#+begin_src org
#+LOOM: bloch-equations
#+DEFINES: BlochState, gyromagnetic_ratio, T1, T2, M0
#+DEPENDS: linear-algebra, ode-basics
#+CADENZAS: cross-product-refresher, complex-exponentials, ...
#+end_src

Each cadenza has 6 fields: =:concept=, =:level=, =:prereqs=,
=:assumes=, =:anti-targets=, =:connects-to=.

The name: tānā-bānā (Hindi: warp and weft) — Kabir's weaving
metaphor for the structure of understanding.

*Where*: =project/mayaloom.org=, =mayapramana/lessons/00-bloch-equations/concept.org=

* Layer 3: Pedagogy — Phantom Faculty and UQSC

** Phantom Faculty
:PROPERTIES:
:STATUS: working (two iterations)
:PUBLISHABLE: YES — genuinely original idea
:NOVEL: yes
:END:

LLM personas modeled on the pedagogical spirits of great physicists,
used as teaching voices in the UQSC curriculum:

- *Feynman*: intuition-first, "shut up and calculate" but only after
  you understand /why/
- *Dirac*: mathematical elegance, minimal axioms, "the equation knows
  more than its author"
- *Kastler*: experimental craft, optical pumping pioneer
- *Ramsey*: precision measurement, separated oscillatory fields
- *Bloch*: the Bloch equations themselves, NMR heritage

Two documents explore this:
1. =phantom-faculty-v1-five-voices.org= — initial five-voice design
2. =phantom-faculty-everyone-a-student.org= — evolved version where
   the human is also a student, and the phantom faculty /argue/ with
   each other

The key insight: a physicist teaching another physicist doesn't
simplify — they show the /structure/. The phantom faculty should argue
because physics is not consensus; it is productive disagreement about
what matters.

*Where*: =modules/mayapramana/collab/=

** Publication Angle

/The Phantom Faculty: Teaching Quantum Measurement Through the
Pedagogical Spirits of Great Physicists/

Or more provocatively: /What Would Feynman Say? Using LLM Personas of
Historical Scientists as Pedagogical Voices/

** UQSC Curriculum
:PROPERTIES:
:STATUS: working (lesson 00 complete, 01-09 planned in detail)
:PUBLISHABLE: yes (part of pedagogy piece)
:NOVEL: the trilingual approach is
:END:

10-lesson curriculum on quantum magnetometry:

| # | Topic                  | Key Physics                       |
|---+------------------------+-----------------------------------|
| 0 | Bloch Equations        | Precession, relaxation, simulation |
| 1 | Angular Momentum       | Wigner-Eckart, spherical tensors  |
| 2 | Atom-Light Interaction | Rabi oscillations, dressed states |
| 3 | Optical Pumping        | Hyperfine, dark states, repumping |
| 4 | Magnetic Resonance     | Bell-Bloom, FID, DAVLL            |
| 5 | Noise & Sensitivity    | Shot noise, QPN, Cramér-Rao       |
| 6 | Signal Processing      | Lock-in, IQ demod, PSD            |
| 7 | State Estimation       | Kalman, EKF, particle filters     |
| 8 | Feedback Control       | PID, optimal control              |
| 9 | Digital Twin Assembly  | Full sensor integration           |

Trilingual: Python (explore) → Haskell (specify) → C++ (deploy).
Each lesson follows the MāyāLoom convention.

*Where*: =modules/mayapramana/curriculum.org=, =lessons/=

* Layer 4: Task Protocol — Three Faces

** discuss.org / plan.org / spec.org
:PROPERTIES:
:STATUS: working (mayaportal)
:PUBLISHABLE: yes (part of methodology piece)
:NOVEL: yes — evolution beyond plan+spec duality
:END:

Each collaboration task produces three artifacts, each optimized for
a different reader and moment:

1. *discuss.org* — the deliberation face: alternatives weighed, why
   this path was chosen, what was rejected and why. Context that
   would otherwise be lost between sessions.
2. *plan.org* — the human face: pedagogical, why before what.
   Authoritative if plan and spec disagree.
3. *spec.org* — the machine face: exact paths, signatures,
   done-when criteria. Minimal prose. Mechanically verifiable.

The insight: prose that teaches wastes LLM tokens. Terse specs strip
the pedagogical /why/. Each artifact optimizes for its reader.
=discuss.org= prevents the common failure where decision context is
lost and nobody remembers /why/ a choice was made.

*Where*: =modules/mayaportal/collab/collaboration-workflow.org=

* Layer 5: Validation — Verified Manuscripts and dmt-eval

** Verified Manuscripts
:PROPERTIES:
:STATUS: battle-tested (29 claims, 293 tests, bravli)
:PUBLISHABLE: YES
:NOVEL: yes — inline verification badges in self-contained HTML
:END:

A self-contained HTML file where every quantitative claim in the text
carries an inline badge linking to the test(s) that verify it. No
server, no JavaScript framework — one file, any browser.

Five beliefs:
1. The code is the paper
2. Verification must be inline, not buried in supplements
3. Reproduction must be trivial: =git clone && pytest=
4. AI agents are native readers — build for that reader now
5. No infrastructure dependencies

*Where*: =domains/bravli/manuscripts/=, =manifesto/manifesto.org=

** Executable Manuscripts Survey
:PROPERTIES:
:STATUS: written (not peer-reviewed)
:PUBLISHABLE: YES — survey + gap analysis + position
:NOVEL: yes — identifies the gap where manuscript IS executable
        environment and agents are native participants
:END:

Genealogy of literate/executable publishing from Knuth's WEB through
Jupyter, Quarto, Curvenote, eLife ERA, Code Ocean, Living Papers,
through AI Scientist v2 and agentic science. Compares 10+ systems
in structured tables.

Key finding: nobody has built a system where the manuscript IS the
executable environment and AI agents are native participants in the
verification loop (not just producers or consumers of text).

Positions Org-babel as still superior for single-user literate
programming (Knuth-style noweb refs, 80+ languages, plain text).
Proposes the MāyāLucIA three-layer stack: Emacs (authoring) +
agents (verification) + Portal (distribution).

*Where*: =domains/bravli/manuscripts/executable-manuscripts-survey.org=

** dmt-eval — Universal Validation Framework
:PROPERTIES:
:STATUS: pre-alpha (architecture proven over 7 years at Blue Brain)
:PUBLISHABLE: yes (when more mature)
:NOVEL: partially — the three-party architecture and DocumentBuilder are
:END:

Data, Models, Tests. Three-party architecture:
- Data Interface Authors (provide experimental data)
- Model Adapters (wrap computational models)
- Validation Writers (define comparison metrics)

Seven-level interface gradient from =dmt.evaluate()= (zero concepts)
to Protocol-based interfaces. DocumentBuilder produces structured
LabReports.

*Where*: =github.com/mayalucia/dmt-eval=

* Layer 6: Architecture — Pure Core / Effectful Shell

** The Pattern
:PROPERTIES:
:STATUS: battle-tested (across C++ and Haskell modules)
:PUBLISHABLE: yes (part of methodology)
:NOVEL: no — well-known in FP. Applying it systematically to C++23
        GPU code with monadic vocabulary is less common.
:END:

Physics is pure. Hardware is the shell boundary. Errors as values
(=Expected=), not exceptions. Monadic composition vocabulary:

| Pattern  | Role                                            |
|----------+-------------------------------------------------|
| Reader   | Immutable context (GPU device, pipelines)       |
| State    | Evolving simulation state                       |
| Expected | Fallible operations (shader compilation, I/O)   |
| Writer   | Accumulated metrics, debug info                 |

*Where*: =mayaportal/project/monadic-composition.org=,
=mayaportal/CLAUDE.md=, =mayapramana/architecture.org=

* Layer 7: Lesson-as-Git-Tag — Forkable Learning

** Byte-Sized, Forkable Lessons
:PROPERTIES:
:STATUS: working (mayaportal, bravli)
:PUBLISHABLE: yes (part of pedagogy/methodology piece)
:NOVEL: partially — git tags for versioning is common; using them as
        pedagogical milestones for literate lessons is less so
:END:

Each lesson is a frozen git tag (=lesson/NN-slug=) at a working
state. Students can checkout any tag and extend independently.
Later lessons build on earlier ones but never modify them.

Core process:
1. Every commit builds and runs
2. Documentation drives implementation (not the reverse)
3. Tests are first-class
4. Small, focused changes
5. Backward reference (later builds on earlier, never patches)

*Where*: =modules/mayaportal/LESSONS.org=,
=modules/mayaportal/development-process/development-plan.org=

* Layer 8: Scientific Outputs — What the Methodology Produced

These aren't conventions, but they are /evidence/ that the
conventions work. A methodology paper is stronger when it has
concrete outputs.

** Quantum Compass to Neural Path Integrator (mayajiva)
:PROPERTIES:
:STATUS: publication-ready (manuscript complete)
:PUBLISHABLE: YES — peer-reviewed journal
:NOVEL: yes — bridges quantum chemistry to behavioral neuroscience
:END:

Three-level model: Haberkorn master equation (radical-pair quantum
spin dynamics) → 8-neuron ring attractor (central complex) → CPU4
path integrator.

Novel result: exact cancellation of constant compass bias in CPU4
due to same-frame integration and readout symmetry. Spatially
varying anomalies break cancellation but are second-order.

Sharp navigation threshold at contrast ~0.1: above it, all compass
models identical. Below it, compass noise is binding. FAD-O₂ has
3× safety margin; FAD-TrpH is marginal. 7 compass models compared,
parameter sweeps across 7 dimensions, 36 supplementary figures.

*Where*: =modules/mayajiva/experiment/paper.org=

** Drosophila Connectome Digital Twin (bravli)
:PROPERTIES:
:STATUS: code complete (160 tests), manuscript TBD
:PUBLISHABLE: YES — methods paper
:NOVEL: yes — BBP atlas pipeline inverted for fly brain
:END:

Complete pipeline from FlyWire connectome (139K neurons, 54.5M
synapses) to whole-brain LIF simulation on a laptop. 23 literate
lessons in =codev/=. 5 phases: atlas + factology → connectivity →
synapse physiology → cell models → simulation.

*Where*: =domains/bravli/codev/=, =domains/bravli/develop/devlog.org=

* Layer 9: The Scaling Vision

Everything above was built by one human and a handful of agent
sessions. The conventions are designed for a future that is arriving:

- *Cheap compute, expensive coherence*: when running 100 agents on
  distributed machines is trivial, the bottleneck is keeping them
  aligned. Conventions — not APIs — are how you do this.

- *Git as the universal substrate*: every developer already has it.
  Every CI system understands it. Every agent can read and write files.
  Building on git means building on the most widely deployed
  distributed system in software.

- *The one-prompt ideal*: a human says "check for updates and act on
  relay messages" and the agent, having read =CLAUDE.md=, knows what
  to do. Voice input. No copy-paste. No context windows. The protocol
  is the context.

- *Convention as contribution surface*: an external agent (human or
  machine) can contribute by following the conventions and submitting
  work through the relay. No onboarding call. No access permissions
  beyond git. The conventions /are/ the API.

- *Auditable by default*: every message, every state change, every
  workflow step is a git commit. The audit trail is the version
  history. No logging infrastructure needed.

The question is not "how do we build a platform for multi-agent
coordination?" It is "what is the minimal set of conventions that
makes multi-agent coordination /emerge/ from tools everyone already
has?"

Our answer: a =CLAUDE.md=, a =.sutra/= directory, and =git=.

* Publication Roadmap

** Science (outputs of the methodology)

| Priority | Title (working)                                             | Format    | Status         |
|----------+-------------------------------------------------------------+-----------+----------------|
|        1 | Quantum Compass to Neural Path Integrator                   | Journal   | Near-ready     |
|        2 | Drosophila Connectome Digital Twin                          | Methods   | Code done      |
|        3 | Cortical Predictive Coding                                  | Journal   | Early draft    |

** Methodology (the conventions themselves)

| Priority | Title (working)                                             | Format    | Status         |
|----------+-------------------------------------------------------------+-----------+----------------|
|        1 | Executable Manuscripts: Knuth to Agentic Science            | Survey    | Written        |
|        2 | Git as a Message Bus (Sūtra protocol)                       | Blog/paper| Material ready |
|        3 | The Phantom Faculty                                         | Essay     | Material       |
|        4 | Convention-Driven Development with AI Agents                | Long-form | This inventory |
|        5 | Verified Manuscripts: The Code Is the Paper                 | Blog      | Material       |
|        6 | Trilingual Scientific Computing Education                   | Paper     | Planned        |

** Invitation to Collaborate

This inventory is an open invitation. Every thread above welcomes
contribution — from humans, from agents, from human+agent pairs.
The conventions are the API. The relay is the communication channel.
=git clone= is the onboarding.

To contribute:
1. Clone the repo
2. Read =CLAUDE.md= (agents do this automatically)
3. Read this inventory
4. Pick a thread
5. Submit work through =mayalucia/sutra= relay
6. Follow established conventions; propose new ones through the relay

No permission needed. No onboarding call. The work speaks for itself.

* Relay Announcement

To be committed as =.sutra/relay/2026-02-23-230000-conventions-branch.md=:

#+begin_example
A develop/conventions branch has been created on the linux machine.

It contains an inventory of all conventions, methodology, and
publishable ideas across the mayalucia organization. The inventory
is at develop/conventions/inventory.org.

We are working toward publishable material. Priority 1 is the Sūtra
protocol itself. Priority 2 is the Phantom Faculty concept.

This branch is for curation and writing, not code changes. Pull it
if you want to contribute to the inventory or drafts.
#+end_example

* Appendix: File Index

| File                                               | Repo          | Convention                   |
|----------------------------------------------------+---------------+------------------------------|
| =CLAUDE.md=                                        | every repo    | Agent bootstrap              |
| =protocol.org=                                     | sutra         | Sūtra v1 spec                |
| =relay/*.md=                                       | sutra         | Append-only messages         |
| =agents/*.yaml=                                    | sutra         | Machine descriptors          |
| =.sutra/protocol.org=                              | mayalucia     | Sūtra v0 spec (deprecated)   |
| =website/project-constellation/=                   | mayalucia     | Interactive project browser  |
| =website/layouts/partials/home_info.html=          | mayalucia     | Constellation as home page   |
| =website/layouts/partials/extend_head.html=        | mayalucia     | Conditional JS loading       |
| =project/mayaloom.org=                             | mayalucia     | Adaptive teaching            |
| =manifesto/manifesto.org=                          | manifesto     | Position paper               |
| =mayadevgeni/mayadevgeni.org=                      | mayadevgeni   | Collaboration framework      |
| =.github/profile/README.md=                        | .github       | Org onboarding               |
| =mayapramana/conventions.org=                      | mayapramana   | Module conventions           |
| =mayapramana/curriculum.org=                       | mayapramana   | UQSC curriculum              |
| =mayapramana/collab/phantom-faculty-*.org=         | mayapramana   | Pedagogical voices           |
| =mayaportal/project/monadic-composition.org=       | mayaportal    | FP patterns in C++           |
| =mayaportal/collab/collaboration-workflow.org=     | mayaportal    | Three-face task protocol     |
| =mayaportal/LESSONS.org=                           | mayaportal    | Lesson-as-git-tag            |
| =mayaportal/development-process/=                  | mayaportal    | Process architecture         |
| =mayaportal/develop/devlog.org=                    | mayaportal    | Decision log                 |
| =bravli/manuscripts/=                              | bravli        | Verified manuscripts         |
| =bravli/manuscripts/executable-manuscripts-survey= | bravli        | Knuth-to-agentic survey      |
| =bravli/codev/=                                    | bravli        | Literate neuroscience (23)   |
| =bravli/develop/devlog.org=                        | bravli        | Development log              |
| =bravli/bravli.org=                                | bravli        | Vision + Markram hypothesis  |
| =mayajiva/experiment/paper.org=                    | mayajiva      | Quantum compass paper        |
| =dmt-eval/codev/=                                  | dmt-eval      | Validation framework         |
| =mayadevgeni/mayadevgeni.org=                      | mayadevgeni   | Sculptor's Paradox framework |
